---
title: "data_exploration"
author: "Joe"
date: "7/11/2018"
output: html_document
---

```{r}
require("RPostgreSQL")
require("tidyverse")
require("leaflet")
require("leaflet.extras")
require("rgdal")
require("RColorBrewer")
```

```{r}
library("tidyverse")
library("dplyr")
mypath <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(mypath)
source(file.path('..', 'connect_to_database.R'), chdir = TRUE)

# mypath <- dirname(rstudioapi::getActiveDocumentContext()$path)
# setwd(mypath)
# 
# # loads the PostgreSQL driver
# drv <- dbDriver("PostgreSQL")
# 
# # make a file called "cred.txt" of the form
# #
# # user: "YOUR_AWS_USERNAME"
# # password: "YOUR_AWS_PASSWORD"
# #
# # in the directory above the osr_dssg2018 folder
# 
# source(file.path(dirname(dirname(mypath)),"../cred.txt"))
# 
# # creates a connection to the postgres database
# # note that "con" will be used later in each connection to the database
# con <- dbConnect(drv, dbname = "dssg2018uw",
#                  host = "localhost", port =9000,
#                  user = user, password = password)
```

```{r}
museums <- dbGetQuery(con, "select * from clean.museums")
libraries <- dbGetQuery(con, "select * from clean.libraries")
fields <- dbGetQuery(con, "select * from clean.fields")
```

Let's look at the percentage of students entering kindegarten, 6th, and 9th grade who are in the choice program. 

```{r}
students <- dbGetQuery(con, "select * from clean.dps_students")
choice <- dbGetQuery(con, "select * from clean.dps_choice")
enrollment <- dbGetQuery(con, "select * from clean.dps_enrollment")

parts <- data.frame()
totals <- data.frame()
for (grade in 0:12) {
  for (given_year in 2014:2018) {
    students_with_choice <- choice %>% filter(spring_year %in% given_year) %>% dplyr::select(student_number)
    students_with_choice <- students_with_choice$student_number
    
    part <- enrollment %>% filter(student_number %in% students_with_choice) %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% nrow
    
    total <- enrollment %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% nrow
    
    parts[as.character(grade),as.character(given_year)] <- part
    totals[as.character(grade),as.character(given_year)] <- total
  }
}

proportion <- parts / totals
print("Percentage of students by grade and year who did choice enrollment:")
print(round(proportion*100,1))
```

Unfortunately, not all of the choice students have an associated address:

```{r}
students_with_locations <- unique(students$student_number[!is.na(students[,"block"])])
print(paste("Number of students who did choice enrollment but don't have address on record:",length(unique(choice$student_number)) - length(students_with_locations)))
```

So we need to additionally get rid of those when considering the percentage of students for whom we have addresses in the given year: 

```{r}
parts_both <- data.frame()
totals_both <- data.frame()
for (grade in 0:12) {
  for (given_year in 2014:2018) {
    
    students_with_choice <- choice %>% filter(spring_year %in% given_year) %>% select(student_number)
    students_with_choice <- students_with_choice$student_number
    
    part <- enrollment %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% filter(student_number %in% students_with_locations) %>% filter(student_number %in% students_with_choice) %>% nrow
    
    total <- enrollment %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% nrow
    
    parts_both[as.character(grade),as.character(given_year)] <- part
    totals_both[as.character(grade),as.character(given_year)] <- total
  }
}

proportion_both <- parts_both / totals_both
print("Percentage of students by grade and year who have address on record and did choice enrollment:")
print(round(proportion_both*100,1))
```

Finally, we want to know which student addresses we actually have by considering that when they choose in one year, we know their address for all years before and all years after. 

```{r}
parts_both <- data.frame()
totals_both <- data.frame()
for (grade in 0:12) {
  for (given_year in 2014:2018) {
    
    part <- enrollment %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% filter(student_number %in% students_with_locations) %>% nrow
    
    total <- enrollment %>% filter(spring_year %in% given_year) %>% filter(grade_level %in% grade) %>% nrow
    
    parts_both[as.character(grade),as.character(given_year)] <- part
    totals_both[as.character(grade),as.character(given_year)] <- total
  }
}

proportion_both <- parts_both / totals_both
print("Percentage of students by grade and year who have address on record:")
print(round(proportion_both*100,1))
```

As a final number, we can simply look at the percentage of students for whom we have addresses, for all years (2011-2018) and for years during which we had student choice (2014-2018):

```{r}
paste("Percentage of students for whom we have addresses:",round(length(students_with_locations)/length(unique(enrollment$student_number))*100,1),"%")
paste("Percentage of students enrolled somewhere between 2014 and 2018 for whom we have addresses:",round(length(students_with_locations)/length(unique(enrollment[enrollment$spring_year %in% 2014:2018,"student_number"]))*100,1),"%")
```

Now we'd like to see how different our choice students are from all other choices, to see whether our sample is biased. 

```{r}
columns = c("race","gender","el_status","primary_disability","has_transportation")
for (column in columns) {
  tmp_df <- data.frame()
  groups <- unique(students[,column])
  for (group in groups) {
    tmp_df[group,"address"] <- round((sum((students$student_number %in% students_with_locations) & (students[,column]==group)) / length(students_with_locations))*100,1)
    tmp_df[group,"no_address"] <- round((sum((!students$student_number %in% students_with_locations) & (students[,column]==group)) / (nrow(students)-length(students_with_locations)))*100,1)
  }
  print(column)
  print(tmp_df)
  barplot(t(tmp_df),beside=TRUE,main=column,cex.names=.5,las=2,legend.text = TRUE)
}
```

Not too bad. Let's also check test scores.

```{r}
test <- dbGetQuery(con, "select * from clean.dps_cmas")

tmp_df <- data.frame()

math_scores <- test[!is.na(test$math_scores),c("student_number","math_scores")]
ela_scores <- test[!is.na(test$ela_scores),c("student_number","ela_scores")]
math_scores <- aggregate(math_scores ~ student_number, data=math_scores, mean)
ela_scores <- aggregate(ela_scores ~ student_number, data=ela_scores, mean)

#to convert raw test scores to standardized z scores
make_z_score <- function(vec) {
  return((vec-mean(vec))/sd(vec))
}

math_scores$math_scores <- make_z_score(math_scores$math_scores)
ela_scores$ela_scores <- make_z_score(ela_scores$ela_scores)

tmp_df["ela","address"] <- mean(ela_scores[ela_scores$student_number %in% students_with_locations,"ela_scores"])
tmp_df["ela","no_address"] <- mean(ela_scores[!ela_scores$student_number %in% students_with_locations,"ela_scores"])
tmp_df["math","address"] <- mean(math_scores[math_scores$student_number %in% students_with_locations,"math_scores"])
tmp_df["math","no_address"] <- mean(math_scores[!math_scores$student_number %in% students_with_locations,"math_scores"])

barplot(t(tmp_df),beside=TRUE,main="Test Score Comparison",cex.names=1,las=2,legend.text = TRUE)
```

```{r}
star <- dbGetQuery(con, "select * from clean.dps_star_reading")

get_mode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

tmp_df <- data.frame()

star_proficiency <- aggregate(reading_level ~ student_number, data=star, get_mode)

groups <- unique(star_proficiency$reading_level)
for (group in groups) {
    tmp_df[group,"address"] <- round((sum((star_proficiency$student_number %in% students_with_locations) & (star_proficiency$reading_level==group))/sum(star_proficiency$student_number %in% students_with_locations))*100,1)
    tmp_df[group,"no_address"] <- round((sum((!star_proficiency$student_number %in% students_with_locations) & (star_proficiency$reading_level==group))/sum(!star_proficiency$student_number %in% students_with_locations))*100,1)
}

barplot(t(tmp_df),beside=TRUE,main="Reading Score Comparison",cex.names=1,las=2,legend.text=TRUE, args.legend = list(x = "topleft"))
```

Finally, we want to understand how discipline differs between the groups of students. 

```{r}
discipline <- dbGetQuery(con, "select * from clean.dps_discipline")

tmp_df <- data.frame()

iss <- discipline[,c("student_number","number_iss")]
oss <- discipline[,c("student_number","number_oss")]
expulsions <- discipline[,c("student_number","number_expulsions")]

iss <- aggregate(number_iss ~ student_number, data=iss, mean)
oss <- aggregate(number_oss ~ student_number, data=oss, mean)
expulsions <- aggregate(number_expulsions ~ student_number, data=expulsions, mean)

tmp_df["in_school_suspension","address"] <- mean(iss[iss$student_number %in% students_with_locations,"number_iss"])
tmp_df["out_of_school_suspension","address"] <- mean(oss[oss$student_number %in% students_with_locations,"number_oss"])
tmp_df["expulsion","address"] <- mean(expulsions[expulsions$student_number %in% students_with_locations,"number_expulsions"])

tmp_df["in_school_suspension","no_address"] <- mean(iss[!iss$student_number %in% students_with_locations,"number_iss"])
tmp_df["out_of_school_suspension","no_address"] <- mean(!oss[oss$student_number %in% students_with_locations,"number_oss"])
tmp_df["expulsion","no_address"] <- mean(expulsions[!expulsions$student_number %in% students_with_locations,"number_expulsions"])

barplot(t(tmp_df),beside=TRUE,main="Average Discipline Record Comparison",cex.names=.7,las=1,legend.text = TRUE)
```

Now we want to consider how many students we have in each block group. First, we'll read in the shape file for block groups:

```{r}
mypath <- getwd()
dataPath <- file.path(dirname(mypath), "data", "census_clean", "shape_census")
spdf <- readOGR(dsn = dataPath,"shape_census")
```

Now let's see where students lie in blocks. We can click on each of the dots (each representing a block) to see how many students live in that block. 

```{r message=FALSE}
block_locations <- dbGetQuery(con, "select * from clean.dps_block_locations")

table_of_blocks <- table(students$block)
blocks_with_student_pop <- data.frame("block"=names(table_of_blocks), "student_pop"=as.vector(table_of_blocks))
blocks_with_student_pop <- merge(block_locations,blocks_with_student_pop,all.x=TRUE)

##############
# set up for visualization:
cutoffs <- c(0,2,4,6,8,10,12,14)
color_vec <- brewer.pal(length(cutoffs),"YlOrRd")

for (i in 1:length(cutoffs)) {
  blocks_with_student_pop$color[blocks_with_student_pop$student_pop>=cutoffs[i]] <- i
}

lab_factor <- rep("",length(cutoffs))
for (i in 1:length(cutoffs)-1) {
  lab_factor[i] <- paste("Between",cutoffs[i],"and",cutoffs[i+1])
}
lab_factor[1] <- paste("Less than",cutoffs[2])
lab_factor[length(cutoffs)] <- paste("Greater than",cutoffs[length(cutoffs)]) 

blocks_with_student_pop$color <- factor(blocks_with_student_pop$color, label = lab_factor)
# end set up for visualization
##############

leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addCircleMarkers(
    data = blocks_with_student_pop,
    stroke = FALSE, fillOpacity = .1, popup = paste("Student population in block:",blocks_with_student_pop$student_pop),
    color = ~colorFactor(color_vec,blocks_with_student_pop$color)(blocks_with_student_pop$color)
  ) %>%
  addLegend(colors = color_vec, labels = lab_factor)
```

And in block groups:

```{r}
block_groups_with_student_pop <- aggregate(student_pop ~ block_group, data=blocks_with_student_pop[,c("block_group","student_pop")], sum)
block_groups_with_student_pop <- merge(spdf[,"Id2"],block_groups_with_student_pop,all.y=TRUE,by.y="block_group",by.x="Id2")

##############
# set up for visualization:
cutoffs <- c(0,25,50,75,100,150,200,300,600)
color_vec <- brewer.pal(length(cutoffs),"YlOrRd")

for (i in 1:length(cutoffs)) {
  block_groups_with_student_pop@data$color[block_groups_with_student_pop@data$student_pop>=cutoffs[i]] <- i
}

lab_factor <- rep("",length(cutoffs))
for (i in 1:length(cutoffs)-1) {
  lab_factor[i] <- paste("Between",cutoffs[i],"and",cutoffs[i+1])
}
lab_factor[1] <- paste("Less than",cutoffs[2])
lab_factor[length(cutoffs)] <- paste("Greater than",cutoffs[length(cutoffs)]) 

block_groups_with_student_pop@data$color <- factor(block_groups_with_student_pop@data$color, label = lab_factor)
# end set up for visualization
##############

leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data = block_groups_with_student_pop, weight=1,
    fillColor = ~colorFactor(color_vec,block_groups_with_student_pop@data$color)(block_groups_with_student_pop@data$color),
    fillOpacity=10,
    popup = paste("Student population:",block_groups_with_student_pop@data$student_pop)
    ) %>%
  addLegend(labels=lab_factor,colors = color_vec)
  
```

Let's compare to census data. 

```{r}
#census <- dbGetQuery(con, "select * from clean.acs_demographics")

age_subset <- c("age_5_to_9","age_10_to_14","age_15_to_17")
block_groups_with_student_and_census_pop <- merge(block_groups_with_student_pop,census[,c("id2",age_subset)],all.x=TRUE,by.x="Id2",by.y="id2")
block_groups_with_student_and_census_pop@data$census_pop <- apply(X = block_groups_with_student_and_census_pop@data[,age_subset], FUN = sum, MARGIN=1)

# block_groups_student_and_census_pop@data$pop_difference <- (block_groups_student_and_census_pop@data$student_pop-block_groups_student_and_census_pop@data$census_pop)

##############
# set up for visualization:
cutoffs <- c(0,25,50,75,100,150,200,300,600)
color_vec <- brewer.pal(length(cutoffs),"YlOrRd")

for (i in 1:length(cutoffs)) {
  block_groups_with_student_and_census_pop@data$color[block_groups_with_student_and_census_pop@data$census_pop>=cutoffs[i]] <- i
}

lab_factor <- rep("",length(cutoffs))
for (i in 1:length(cutoffs)-1) {
  lab_factor[i] <- paste("Between",cutoffs[i],"and",cutoffs[i+1])
}
lab_factor[1] <- paste("Less than",cutoffs[2])
lab_factor[length(cutoffs)] <- paste("Greater than",cutoffs[length(cutoffs)]) 

block_groups_with_student_and_census_pop@data$color <- factor(block_groups_with_student_and_census_pop@data$color, label = lab_factor)
# end set up for visualization
##############

leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data = block_groups_with_student_and_census_pop, weight=1,
    fillColor = ~colorFactor(color_vec,block_groups_with_student_and_census_pop@data$pop_difference)(block_groups_with_student_and_census_pop@data$pop_difference),
    fillOpacity=10,
    popup = paste(block_groups_with_student_and_census_pop@data$pop_difference, "Choice population:",block_groups_with_student_and_census_pop@data$student_pop,"Census population:",block_groups_with_student_and_census_pop@data$census_pop)
    ) %>%
  addLegend(labels=lab_factor,colors = color_vec)
```

We also want to know how the demographics compare. Unfortunately, we don't have demographics on school age kids by race; we separately have demographics for given age groups and given ages. To first order, we will instead therefore just weight the demographics of each block group by the percent of people in the block who are school age (this assumes that the demographics within the block are the same for all ages, but captures the fact that, for example, a block with a retirement home and mostly old white people shouldn't contribute a lot of student white people to the demographic histogram).  

```{r}
tmp_df <- data.frame()
student_races <- sort(unique(students[,"race"]))
census_races <- c("asian","black","hispanic","americanindian","pacificislanders","two_or_more_races","white")

for (i in 1:length(census_races)) {
  tmp_df[student_races[i],"student"] <- round((sum((students$student_number %in% students_with_locations) & (students[,"race"]==student_races[i])) / length(students_with_locations))*100,1)
  tmp_df[student_races[i],"census"] <- sum(census[,census_races[i]]*((apply(FUN=sum,X=census[,age_subset],MARGIN=1))/census[,"ttl_population"]))
}
tmp_df[,"census"] <- round(((tmp_df[,"census"])/sum(tmp_df[,"census"]))*100,1)
print(tmp_df)
barplot(t(tmp_df),beside=TRUE,main="Census vs Student Choice Demographics",cex.names=.5,las=2,legend.text = TRUE)
```

### BLUEPRINT4SUMMER ###

Now we'll move on to analyzing Blueprint4Summer search data, which includes the zip code searched for. 

```{r}
google_analytics <- dbGetQuery(con, "select * from clean.google_analytics")
programs <- dbGetQuery(con, "select * from clean.reschool_summer_programs")
```

We'll get shape files for all zip codes from online. 

```{r}
library("rgdal")

# Read shapefile into SpatialPointsDataFrame.
spdf <- readOGR(dsn = "../data/zip_codes", "cb_2017_us_zcta510_500k")

spdf@data$GEOID10 <- as.character(spdf@data$GEOID10)
```

Consider all zip codes included in the search data (some of which are outside of Denver, and some are missing from the set of Denver zip codes).

```{r}
google_analytics$location <- gsub(".*(80\\d{3}).*","\\1",google_analytics$location)
searches_with_locations <- google_analytics[grep("80\\d{3}",google_analytics$location),]
unique_search_locations <- unique(searches_with_locations$location)
```

The zip codes we care to save are those in the search data and those in Denver generally. After running for the first time, you can simply use the zip_codes in the future. 

```{r}
relevant_zip_codes <- spdf[spdf@data$GEOID10 %in% unique_search_locations,]
# create a shapefile so we don't have to push such a large dataset
writeOGR(relevant_zip_codes,"../data/zip_codes","zip_codes", driver="ESRI Shapefile")
relevant_zip_codes <- readOGR(dsn="../data/zip_codes")
```

Oddly enough, 3 of the searched zip codes don't exist:

```{r}
unique_search_locations[!unique_search_locations %in% relevant_zip_codes@data$GEOID10]
```

Let's check out the frequencies of searches by zip code:

```{r}
table(searches_with_locations$location)
```

We'll be excluding 2+3+7=12 zip codes, but for now let's just forget them and move on (we'll still have 3,000 searches total):

```{r}
searches_with_locations <- searches_with_locations[searches_with_locations$location %in% unique_search_locations[unique_search_locations %in% relevant_zip_codes@data$GEOID10],]

table(searches_with_locations$location)
```

We can look at the included areas with leaflet, weighted by the number of searches in that area:

```{r}
search_frequencies <- as.vector(table(searches_with_locations$location))
leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data = relevant_zip_codes,
    fillColor = ~colorQuantile("YlOrRd",search_frequencies)(search_frequencies),
    popup = as.character(search_frequencies)
    ) %>%
  addCircleMarkers(
    data=programs,
    radius=5,
    popup = programs$camp_name
  ) %>%
  addScaleBar() %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```

We also can look at the distribution of programs by type.

We'll begin by considering where athletic programs are. We note that there are very few in the north, which also is a lower income community. 

```{r}
colors5 <- c('#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026') 

popup_string="Income:"
col_name="Mdn_HH_"

spdf@data$color <- 1
breaks <- c(30000,50000,70000,90000)
for (i in 1:length(breaks)) {
  spdf@data$color[spdf@data[,col_name] > breaks[i]] <- i+1
}

lab_factor <- c("Less than 30,000", 
                "Between 30,000 and 50,000", 
                "Between 50,000 and 70,000", 
                "Between 70,000 and 90,000",
                "Greater than 90,000")
spdf@data$color <- factor(spdf@data$color, label = lab_factor)

#search_frequencies <- as.vector(table(searches_with_locations$location)
leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data=spdf,
    fillColor = ~colorFactor(colors5,spdf@data[,col_name])(spdf@data[,col_name]),
    opacity=.1,
    popup = paste(popup_string,round((spdf@data[,col_name]),1)),
    fillOpacity = 1,
    weight=1
  ) %>%
  addLegend(colors=colors5,labels=lab_factor) %>%
  addCircleMarkers(
    data=programs[programs$has_sports,],
    color='green',
    opacity=10,
    radius=2,
    popup=programs[programs$has_athletic,"session_name"]
  ) %>%
  # addCircleMarkers(
  #   data=fields,
  #   color='blue',
  #   radius=2,
  #   popup=fields$sport
  # ) %>%
  addLegend(labels=c('athletic programs'),
            colors=c('green')
  ) %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```

```{r}
colors5 <- c('#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026') 

popup_string="Income:"
col_name="Mdn_HH_"

spdf@data$color <- 1
breaks <- c(30000,50000,70000,90000)
for (i in 1:length(breaks)) {
  spdf@data$color[spdf@data[,col_name] > breaks[i]] <- i+1
}

lab_factor <- c("Less than 30,000", 
                "Between 30,000 and 50,000", 
                "Between 50,000 and 70,000", 
                "Between 70,000 and 90,000",
                "Greater than 90,000")
spdf@data$color <- factor(spdf@data$color, label = lab_factor)

#search_frequencies <- as.vector(table(searches_with_locations$location)
leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data=spdf,
    fillColor = ~colorFactor(colors5,spdf@data[,col_name])(spdf@data[,col_name]),
    opacity=.1,
    popup = paste(popup_string,round((spdf@data[,col_name]),1)),
    fillOpacity = 1,
    weight=1
  ) %>%
  addLegend(colors=colors5,labels=lab_factor) %>%
  addCircleMarkers(
    data=programs,#[programs$has_sports,],
    color='green',
    opacity=10,
    radius=2,
    popup=programs$session_name#[programs$has_athletic,"session_name"]
  ) %>%
  # addCircleMarkers(
  #   data=fields,
  #   color='blue',
  #   radius=2,
  #   popup=fields$sport
  # ) %>%
  addLegend(labels=c('athletic programs'),
            colors=c('green')
  ) %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```

Interestingly, there are resources already there which could be used for sports programs. Mapping also athletic fields:

```{r}
colors5 <- c('#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026') 

popup_string="Income:"
col_name="Mdn_HH_"

spdf@data$color <- 1
breaks <- c(30000,50000,70000,90000)
for (i in 1:length(breaks)) {
  spdf@data$color[spdf@data[,col_name] > breaks[i]] <- i+1
}

lab_factor <- c("Less than 30,000", 
                "Between 30,000 and 50,000", 
                "Between 50,000 and 70,000", 
                "Between 70,000 and 90,000",
                "Greater than 90,000")
spdf@data$color <- factor(spdf@data$color, label = lab_factor)

#search_frequencies <- as.vector(table(searches_with_locations$location)
leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data=spdf,
    fillColor = ~colorFactor(colors5,spdf@data[,col_name])(spdf@data[,col_name]),
    opacity=.1,
    popup = paste(popup_string,round((spdf@data[,col_name]),1)),
    fillOpacity = 1,
    weight=1
  ) %>%
  addLegend(colors=colors5,labels=lab_factor) %>%
  addCircleMarkers(
    data=programs[programs$has_sports,],
    color='green',
    opacity=10,
    radius=2,
    popup=programs[programs$has_sports,"session_name"]
  ) %>%
  # addCircleMarkers(
  #   data=fields,
  #   color='blue',
  #   radius=2,
  #   popup=fields$sport
  # ) %>%
  addLegend(labels=c('athletic programs',''),
            colors=c('green','blue')
  ) %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```


```{r}
# Thanks Haowen
colors5 <- c('#ffffb2','#fecc5c','#fd8d3c','#f03b20')#,'#bd0026') 

popup_string="Black percentage:"
col_name="PCT_Afr"

spdf@data$color <- 1
breaks <- c(20,40,60)
for (i in 1:length(breaks)) {
  spdf@data$color[spdf@data[,col_name] > breaks[i]] <- i+1
}

lab_factor <- c("Less than 20", 
                "Between 20 and 40", 
                "Between 40 and 60", 
                "Between 60 and 80")
                #"Greater than 80")
spdf@data$color <- factor(spdf@data$color, label = lab_factor)

#search_frequencies <- as.vector(table(searches_with_locations$location)
leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data=spdf,
    fillColor = ~colorFactor(colors5,spdf@data[,col_name])(spdf@data[,col_name]),
    opacity=.1,
    popup = paste(popup_string,round((spdf@data[,col_name]),1)),
    fillOpacity = 1,
    weight=1
  ) %>%
  addLegend(colors=colors5,labels=lab_factor) %>%
  addCircleMarkers(
    data=programs[programs$has_sports,],
    color='green',
    opacity=10,
    radius=2,
    popup=programs[programs$has_sports,"session_name"]
  ) %>%
  # addCircleMarkers(
  #   data=fields,
  #   color='blue',
  #   radius=2,
  #   popup=fields$sport
  # ) %>%
  addLegend(labels=c('athletic programs','fields'),
            colors=c('green','blue')
  ) %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```

We can look at the locations of the searchers (based on IP address), and we find that there are unfortunately only 2 distinct locations in Denver.

```{r}
google_analytics_aggregated <- aggregate(users ~ lat + long, data=google_analytics, sum)

leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  # addCircleMarkers(
  #   data = google_analytics %>% filter(lat < 39.8 & long > -105.1 & lat > 39.6 & long < -104.8),
  #   stroke = FALSE, fillOpacity = .5, color = 'blue'
  # ) %>%
  addCircleMarkers(
    data = google_analytics_aggregated,
    stroke = FALSE, fillOpacity = .5, color = 'yellow', popup = as.character(google_analytics_aggregated$users)
  ) %>%
  setView(lat=39.7,lng=-104.9,zoom=10)
```

We also would like to understand how long programs generally last: 

```{r}
programs$length <- as.numeric(as.Date(programs[!duplicated(programs$session_id),"session_date_end"]) - as.Date(programs[!duplicated(programs$session_id),"session_date_start"]))
print(table(programs[!duplicated(programs$session_name),]$length))
plot(table(programs[!duplicated(programs$session_name),]$length))
```

One big fear for the access index is that we will need to adjust program cost, or potentially even transportation time, for the number of days the programs last. By manual inspection of the websites for the programs the program with 119 is online, and some of the monthlong ones meet just once a week. So we may have to manually check those that are greater than about 4 days. 

```{r}
sum(programs[!duplicated(programs$session_name),]$length > 4)
```

Manually inputting the true number of days would be somewhat time-consuming, though doable. But the main problem is that it would not be very reproducible.

```{r}
#when you're done, close the connection and unload the driver 
dbDisconnect(con) 
dbUnloadDriver(drv)
```

```{r}
View(programs)
```
