---
title: "Denver Open Data Processing - Programs and Resources"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Uncomment the line below if you're using RStudio to run the file
# (don't use if you're running knitr)
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))  # makes sure data files are saved in same location as this file
```

Load the necessary libraries. 

```{r libs, message=FALSE, results="hide"}
library(tidyverse)
library(rgdal)  # for working with spatial data frames
library(rgeos)  # for working with spatial data frames
library(splitstackshape)  # for splitting strings and turning into binary columns
library(gsheet)  # only needed for the afterschool programs, to merge with annotated data
```

Some functions we will need for data processing:

```{r functions, message=FALSE, results="hide"}
# Create a directory in the current working directory, if one with the given name doesn't exist yet
#    input:   name of directory to create (string)
#    output:  n/a
MakeDir <- function(dirName) {
  dataDir <- file.path(getwd(), dirName)
  if (!dir.exists(dataDir)) {
    dir.create(dataDir)
  }
}

# Function to load data from Denver Open Data shapefiles
#     input:   name of zip file - see url where data resides to find this (string)
#     output:  SpatialPointsDataFrame or SpatialPolygonsDataFrame with shapefile data
GetOpenData <- function(zipname) {
  MakeDir("raw_data")  # make a raw data directory, if one doesn't exist yet
  
  # Download .zip to raw data directory, then unzip in temporary directory.
  url <- paste("https://www.denvergov.org/media/gis/DataCatalog/", zipname, "/shape/", zipname, ".zip", sep="")
  tempDir <- tempdir()
  file <- file.path("raw_data", paste(zipname, ".zip", sep=""))
  download.file(url, file)
  unzip(file, exdir = tempDir)
  
  # Read in shapefile from unzipped data and return result
  spdf <- readOGR(dsn = tempDir, zipname)
  return(spdf)
}

# Function to turn a SpatialPolygonsDataFrame into a flat csv
#    input:   SpatialPolygonsDataFrame and filename (string) for the saved csv
#    output:  n/a
#    note:    saves the csv to clean_data directory (within current working directory), 
#             csv has SPDF data + centroid lat/long + polygon area in square feet
SavePolygonsAsCSV <- function(spdf, filename) {
  # Compute centroids of polygons and save to data frame
  centroids <- SpatialPointsDataFrame(gCentroid(spdf, byid=TRUE), spdf@data, match.ID=FALSE) 
  centroids <- as.data.frame(centroids)
  colnames(centroids)[colnames(centroids)=="x"] <- "long"  # for consistency across files
  colnames(centroids)[colnames(centroids)=="y"] <- "lat"  # for consistency across files
  
  # Compute area in sqft of each polygon and add to data frame
  equalAreaProj <- spTransform(spdf, CRS("+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=ft +no_defs"))
  centroids$sqft <- gArea(equalAreaProj, byid=TRUE)
  
  # Save result to csv
  MakeDir("clean_data")  # make a clean data directory, if one doesn't exist yet
  write.csv(centroids, file=file.path("clean_data",filename), row.names=FALSE)
}

# Function to turn a SpatialPointsDataFrame into a flat csv
#    input:   SpatialPointsDataFrame and filename (string) for the saved csv
#    output:  n/a
#    note:    saves the csv to clean_data directory (within current working directory), 
#             csv has SPDF data + lat/long
SavePointsAsCSV <- function(spdf, filename) {
  # Get and format lat/long info
  df <- as.data.frame(spdf)
  colnames(df)[colnames(df)=="coords.x1"] <- "long"  # for consistency across files
  colnames(df)[colnames(df)=="coords.x2"] <- "lat"  # for consistency across files
 
  # Save result to csv
  MakeDir("clean_data") # make a clean data directory, if one doesn't exist yet 
  write.csv(df, file=file.path("clean_data",filename), row.names=FALSE)
}

# Function to split a column that contains comma-separated lists into separate binary columns
#    input:   dataframe, column name (string) containing comma-separated lists to split
#    output:  dataframe, with binary (0/1) columns replacing the specified column
SplitCommas <- function(df, colname) {
  df[[colname]] <- as.character(df[[colname]])
  dfSplit <- cSplit_e(df, colname, sep = ",", mode = "binary",
         type = "character", fill = 0, drop = TRUE)
  return(dfSplit)
}
```

Now we're ready to get into the data!

## Afterschool Programs

First we look at afterschool programs.

```{r, results="hide"}
afterSchool <- GetOpenData("afterschool_programs")
```

Merge the Denver Open Data with our manual annotations of program type (done in Google Sheets), which include the same categories as Blueprint4Summer (academic, arts, cooking, dance, drama, music, nature, sports, stem), as well as additional annotations (which we will ignore).

```{r, google}
# Get the data from the google sheet
gurl <- construct_download_url('https://docs.google.com/spreadsheets/d/1nnz6fKMPNJSIjN8eSQ2axwORCt7JV-_w0tzbsg5NkJ0/edit?usp=sharing')
gsheetData <- as.data.frame(gsheet2tbl(gurl))

# Merge the annotations into the original data
afterSchoolFull <- merge(x = afterSchool, y = gsheetData)

# Replace NA's by 0's in annotated columns.
for (colnum in 14:29) {
  afterSchoolFull@data[is.na(afterSchoolFull@data[,colnum]),colnum] <- 0
}

# Sanity checks about the results
colSums(is.na(afterSchoolFull@data)) # check for any leftover NAs
head(afterSchoolFull)
```

Next, subset to only the variables existing in the Blueprint4Summer data, and rewrite column names to be more understandable.

```{r, ASfinal}
afterSchoolFinal <- afterSchoolFull[, c('LOC_NAME', 'ORGANIZATI', 'mAcademic', 'mArts', 'mCooking', 'mDance', 'mDrama', 'mMusic', 'mNature', 'mSports', 'mStem', 'mGirls Program', 'DESCRIPTIO')]

colnames(afterSchoolFinal@data) <- c('location', 'organization', 'has_academic', 'has_arts', 'has_cooking', 'has_dance', 'has_drama', 'has_music', 'has_nature', 'has_sports', 'has_stem', 'girls_only', 'description')

head(afterSchoolFinal)
```

All done! We save the result as a csv.

```{r}
SavePointsAsCSV(afterSchoolFinal, "afterschool.csv")
```

## Rec Centers

Next, we look at recreation centers.

```{r, results="hide"}
recCenters <- GetOpenData("recreation_centers")
```

```{r}
colnames(recCenters@data)
head(recCenters)
```

Delete unuseful columns (urls, links to pdfs and photos, address info, contact info, hours) (Note: 'FACILITIES' is an old version of 'MARKETED_F' which is marketed facilities.)

```{r}
recSmall <- recCenters[, c('REC_NAME', 'REC_TYPE', 'MARKETED_F', 'MARKETED_P', 'YEAR_BUILT', 'YEAR_REMOD', 'BLDG_SQFT', 'LABEL')]
colnames(recSmall@data) <- c('name', 'type', 'FACILITIES', 'PROGRAMS', 'year_built', 'year_remodeled', 'bldg_sqft', 'short_name')
head(recSmall)
```

Split up the facility categories (currently contains lists of facilities in a single column) into separate, binary columns. Only keep the meaningful columns.

```{r}
# Turn each facility type into a column
recFinal <- SplitCommas(recSmall, 'FACILITIES')
colnames(recFinal@data)

# Compute interesting facility distinctions: HAS_CARDIO, HAS_WEIGHTS, HAS_POOL
recFinal@data$has_cardio <- pmax(recFinal@data$FACILITIES_Aerobics, recFinal@data$FACILITIES_Cardio.Eqpmnt, recFinal@data$FACILITIES_Cardio.Eqpmt)

recFinal@data$has_weights <- recFinal@data$FACILITIES_Weight.Room

# we won't use pools anymore, since there is a separate dataset about pools!
# recFinal@data$has_pool <- pmax(recFinal@data$FACILITIES_Pool..Indoor., recFinal@data$FACILITIES_Pool..Outdoor.,recFinal@data$FACILITIES_Indoor.Kiddie.Pool)

recFinal@data$has_gym <- pmax(recFinal@data$FACILITIES_Gym..Large., recFinal@data$FACILITIES_Gym..Reg..Size.,recFinal@data$FACILITIES_Gym..Small.)

# Delete unnecessary columns
recFinal@data[,8:35] <- NULL
```

Similarly, split up the program categories into separate, binary columns.

```{r}
# Turn each facility type into a column
recFinal <- SplitCommas(recFinal, 'PROGRAMS')
colnames(recFinal@data)

# Combine aquatics programs into one column
recFinal@data$has_aquatics <- pmax(recFinal@data$PROGRAMS_Aquatics, recFinal@data$PROGRAMS_Aquatics..using.Wash.Park.Pool.)
recFinal@data[,10:11] <- NULL

# Rename the rest of the binary columns
colnames(recFinal@data)[10:17] <- c("has_arts_culture", "has_day_camps", "has_educ_programs", "has_fitness_health_programs", "has_senior_programs", "has_social_enrich_clubs", "has_special_events", "has_sports")

head(recFinal)
```

All done! We save the result as a csv.

```{r}
SavePointsAsCSV(recFinal, "rec_centers.csv")
```

## Athletic fields

Next, look at athletic fields.

```{r, results="hide"}
fields <- GetOpenData("athletic_fields")
```

```{r}
colnames(fields@data)
head(fields@data)
```

Subset to useful variables and rename columns for simplicity.

```{r}
fieldsSmall <- fields[, c('FEATURE', 'LOCATION', 'FIELD_TIER', 'CLASS_CATE')]
colnames(fieldsSmall@data) <- c('sport', 'location', 'tier', 'class')
head(fieldsSmall@data)
```

Save final product as a csv.

```{r}
SavePolygonsAsCSV(fieldsSmall, "fields.csv")
```

## Playgrounds

Next, look at playgrounds.

```{r, results="hide"}
playgrounds <- GetOpenData("playgrounds")
```

```{r}
colnames(playgrounds@data)
head(playgrounds@data)
```

Subset to useful variables and rename columns for simplicity.

```{r}
playgroundsSmall <- playgrounds[, c('LOCATION', 'YEAR_REHAB', 'CLASS_CATE')]
colnames(playgroundsSmall@data) <- c('location', 'year_rehab', 'class')
head(playgroundsSmall@data)
```

Save final product as a csv.

```{r}
SavePolygonsAsCSV(playgroundsSmall, "playgrounds.csv")
```

## Skate Parks

Next, look at skate parks. There are only 5 of them.

```{r, results="hide"}
skateParks <- GetOpenData("skate_parks")
```

Look at data and subset to useful values, then save.

```{r}
head(skateParks@data)

skateParks <- skateParks[,c(1,4)]
colnames(skateParks@data) <- c('location', 'size')
levels(skateParks@data$size) <- c("large", "small")
head(skateParks@data)

SavePolygonsAsCSV(skateParks, "skate_parks.csv")
```

## Rec Court Surfaces

Next look at recreational court surfaces. From the description on Denver Open Data, these are: "Polygon representation of recreational courts or other playing surfaces such as basketball, tennis, handball, bocce, sand volleyball, horseshoepits, and lawn bowling in parks, golf courses, and other areas maintained by the Department of Parks and Recreation in the City and County of Denver."

```{r, results="hide"}
courts <- GetOpenData("recreational_court_surfaces")
```

Look at data and subset to useful values, then save the result.

```{r}
head(courts@data)

courtsSmall <- courts[,c(1,2,7,8)]
colnames(courtsSmall@data) <- c('sport', 'location', 'year_built', 'year_resurfaced')

SavePolygonsAsCSV(courtsSmall, "courts.csv")
```

## Libraries

Next we look at libraries.

```{r, results="hide"}
libraries <- GetOpenData("libraries")
```

A lot of this info is redundant, such as abbreviations, address/state/zip (which is contained in the shapefile metadata). Other info is unnecessary, such as the status (whether under construction, temporary construction, etc). We also will rename the columns to understandable names.

Look at the data, subset, retype columns, and then save result.

```{r}
head(libraries)

libraries <- libraries[,c(1,9,10,11)]
names(libraries) <- c("name","patron_count","circulation_volume","sqft")

# make sure the types are correct
libraries[["name"]] <- as.character(libraries[["name"]])
libraries[["patron_count"]] <- as.numeric(as.character(libraries[["patron_count"]]))
libraries[["circulation_volume"]] <- as.numeric(as.character(libraries[["circulation_volume"]]))
libraries[["sqft"]] <- as.numeric(as.character(libraries[["sqft"]]))

head(libraries)

SavePointsAsCSV(libraries, "libraries.csv")
```

## Swimming Pools

Next we look at swimming pools.

```{r, results="hide"}
pools <- GetOpenData("swimming_pools")
```

Look at and subset the data, then save to csv.

```{r}
pools <- pools[,c(1,3,11)]
names(pools) <- c("name","type","location")

head(pools)

SavePointsAsCSV(pools, "pools.csv")
```

## Licensed Childcare Facilities

Next we look at childcare facilities.

```{r, results="hide"}
care <- GetOpenData("licensed_child_care_facilities")
```

Look at and subset data, then save.

```{r}
summary(care)

care <- care[c(2,5)]
names(care) <- c("name", "license_type")
levels(care@data$license_type) <- c("center", "home")

head(care)

SavePointsAsCSV(care, "licensed_child_care.csv")

```

## Parks

Finally, look at parks.

```{r, results="hide"}
parks <- GetOpenData("parks")
```

Look at and subset parks data.

```{r}
head(parks@data)

parks <- parks[c(2,5,23)]
names(parks) <- c("name","class","facilities")
parks[["name"]] <- as.character(parks[["name"]])
```

Split facilities lists into separate columns. Only keep 

```{r}
parks <- SplitCommas(parks, "facilities")
colSums(parks@data[,3:194])

# What columns do we have now?
colnames(parks@data)

# Add variable about whether the park has some kind of natural area
natureBool <- grepl("Nature|nature|NATURE|Natural|natural|NATURAL", colnames(parks@data))
colnames(parks@data)[natureBool]  # look at what columns you're getting
parks@data$has_nature <- apply(parks@data[,natureBool], 1, max)

# Add variable about whether the park has a garden
gardenBool <- grepl("Garden|garden|GARDEN", colnames(parks@data))
colnames(parks@data)[gardenBool]  # look at what columns you're getting
parks@data$has_garden <- apply(parks@data[,gardenBool], 1, max)

# Add variable about whether the park has a trail.
trailBool <- grepl("Trail|trail|TRAIL", colnames(parks@data))
colnames(parks@data)[trailBool]  # look at what columns you're getting
parks@data$has_trail <- apply(parks@data[,trailBool], 1, max)
parks@data$has_trail <- NULL  # actually ignore this variable because they all have trails (lol)

# bike paths
bikeBool <- grepl("Bike|bike|BIKE|cycle|Cycle|CYCLE", colnames(parks@data))
colnames(parks@data)[bikeBool]  # look at what columns you're getting
parks@data$has_biking <- apply(parks@data[,bikeBool], 1, max)

# delete the extra variables
parks@data[,3:194] <- NULL

SavePolygonsAsCSV(parks, "parks.csv")
```

## Make the codebook

Build the codebook, i.e. get variable names for each csv saved above in clean_data. Save the results as a csv for easy referencing later.

```{r}
filenameList <- c("afterschool.csv", "courts.csv", "fields.csv", "libraries.csv", "licensed_child_care.csv", "parks.csv", "playgrounds.csv", "pools.csv", "rec_centers.csv", "skate_parks.csv")

maxVars <- 50
codebook <- data.frame(matrix(nrow=maxVars, ncol=0))

for (filename in filenameList) {
  # load csv into workspace
  file <- read.csv(file.path("clean_data",filename) )
  
  vars <- rep(NA, maxVars)
  vars[1:length(names(file))] <- names(file)
  
  # save column names to dataframe
  codebook[[filename]] <- vars
}

write.csv(codebook, file=file.path("clean_data","codebook_resources.csv"), row.names=FALSE)
```

Here is a function for getting the unique values in a column, too, which will be useful for the "values" section in the codebook (but only for the variables for which this is relevant: i.e. the factors). We'll use this on specified columns later, but I won't put it in the markdown becuase that seems excessive.

```{r}
# Function to get codes from a particular column in a data frame
#    input:   data frame, column name (string)
#    output:  list of codes used in that column
GetCodes <- function(df, colName) {
  vals <- sort(unique(df[[colName]]))
  print(vals)
}
```