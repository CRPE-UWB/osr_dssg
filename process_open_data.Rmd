---
title: "Processing Denver Open Data on Programs and Resources"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the necessary libraries.

```{r libs, message=FALSE, results="hide"}
library(tidyverse)
library(rgdal)
library(rgeos)
library(gsheet)  # only needed for the afterschool programs, to merge with annotated data
library(splitstackshape)  # for splitting strings and turning into binary columns
```

Write a function that downloads shapefiles from the Denver Open Data site, and outputs a SpatialPointsDataFrame or SpatialPolygonsDataFrame.

```{r functions, message=FALSE, results="hide"}
# Function to split a column that's a list into separate binary columns
SplitCommas <- function(df, colname) {
  df[[colname]] <- as.character(df[[colname]])
  dfSplit <- cSplit_e(df, colname, sep = ",", mode = "binary",
         type = "character", fill = 0, drop = TRUE)
  return(dfSplit)
}

# Function to load data from Denver Open Data shapefiles
#     input:   name of zip file (see url where data resides to find this)
#     output:  SpatialPointsDataFrame or SpatialPolygonsDataFrame with shapefile data
GetOpenData <- function(zipname) {
  # Download .zip to current directory, then unzip in temporary directory.
  url <- paste("https://www.denvergov.org/media/gis/DataCatalog/", zipname, "/shape/", zipname, ".zip", sep="")
  tempDir <- tempdir()
  print(tempDir)
  file <- basename(url)
  download.file(url, file)
  unzip(file, exdir = tempDir)
  
  # Read shapefile
  spdf <- readOGR(dsn = tempDir, zipname)
  return(spdf)
}

# Function to turn a SpatialPolygonsDataFrame into a flat csv
#    input: SpatialPolygonsDataFrame and filename (string) for the saved csv
#    output: n/a (saves the csv though, with SPDF data + centroid lat/long + polygon area in square feet)
SavePolygonsAsCSV <- function(spdf, filename) {
  # Compute centroids of polygons and save to data frame
  centroids <- SpatialPointsDataFrame(gCentroid(spdf, byid=TRUE), spdf@data, match.ID=FALSE) 
  centroids <- as.data.frame(centroids)
  colnames(centroids)[colnames(centroids)=="x"] <- "long"  # for consistency across files
  colnames(centroids)[colnames(centroids)=="y"] <- "lat"  # for consistency across files
  
  # Compute area in sqft of each polygon
  equalAreaProj <- spTransform(spdf, CRS("+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=ft +no_defs"))
  centroids$sqft <- gArea(equalAreaProj, byid=TRUE)
  
  # Save
  write.csv(centroids, file=filename, row.names=FALSE)
}

# Function to turn a SpatialPointsDataFrame into a flat csv
#    input: SpatialPointsDataFrame and filename (string) for the saved csv
#    output: n/a (saves the csv though, with SPDF data + lat/long
SavePointsAsCSV <- function(spdf, filename) {
  df <- as.data.frame(spdf)
  colnames(df)[colnames(df)=="coords.x1"] <- "long"  # for consistency across files
  colnames(df)[colnames(df)=="coords.x2"] <- "lat"  # for consistency across files
  
  write.csv(df, file=filename, row.names=FALSE)
}
```

## Afterschool Programs

The first dataset we will look at is afterschool programs. First we get the data:

```{r, results="hide"}
afterSchool <- GetOpenData("afterschool_programs")
```

Next we merge with our manual annotations of program type (done in Google Sheets), which include the same categories as Blueprint4Summer (academic, arts, cooking, dance, drama, music, nature, sports, stem), as well as additional annotations.

```{r, google}
# Get the data from the google sheet
gurl <- construct_download_url('https://docs.google.com/spreadsheets/d/1nnz6fKMPNJSIjN8eSQ2axwORCt7JV-_w0tzbsg5NkJ0/edit?usp=sharing')
gsheetData <- as.data.frame(gsheet2tbl(gurl))

# Merge the annotations into the original data
afterSchoolFull <- merge(x = afterSchool, y = gsheetData)

# Replace NA's by 0's in annotated columns.
for (colnum in 14:29) {
  afterSchoolFull@data[is.na(afterSchoolFull@data[,colnum]),colnum] <- 0
}
colSums(is.na(afterSchoolFull@data)) # check for any leftover NAs
```

Next, subset to only the columns consistent with ones existing in the Blueprint4Summer data, and rewrite column names to be more understandable.

```{r, ASfinal}
afterSchoolFinal <- afterSchoolFull[, c('LOC_NAME', 'ORGANIZATI', 'mAcademic', 'mArts', 'mCooking', 'mDance', 'mDrama', 'mMusic', 'mNature', 'mSports', 'mStem', 'mGirls Program', 'DESCRIPTIO')]

colnames(afterSchoolFinal@data) <- c('location', 'organization', 'academic', 'arts', 'cooking', 'dance', 'drama', 'music', 'nature', 'sports', 'stem', 'girls_only', 'description')
head(afterSchoolFinal)
```

All done! We save the result as a csv.

```{r}
SavePointsAsCSV(afterSchoolFinal, "afterschool.csv")
```

## Rec Centers

Next, we look at recreation centers. First, get and look at the data.

```{r, results="hide"}
recCenters <- GetOpenData("recreation_centers")
```

```{r}
colnames(recCenters@data)
head(recCenters)
```

Delete unuseful columns (urls, links to pdfs and photos, address info, contact info, hours) (Note: 'FACILITIES' is an old version of marketed facilities.)

```{r}
recSmall <- recCenters[, c('REC_NAME', 'REC_TYPE', 'MARKETED_F', 'MARKETED_P', 'YEAR_BUILT', 'YEAR_REMOD', 'BLDG_SQFT', 'LABEL')]
colnames(recSmall@data) <- c('name', 'rec_type', 'FACILITIES', 'PROGRAMS', 'year_built', 'year_remodeled', 'bldg_sqft', 'short_name')
head(recSmall)
```

Split up the facility categories (currently contains lists of facilities in a single column) into separate, binary columns.

```{r}
# Turn each facility type into a column
recFinal <- cSplit_e(recSmall, "FACILITIES", sep = ",", mode = "binary",
         type = "character", fill = 0, drop = TRUE)
colnames(recFinal@data)

# Compute interesting facility distinctions: HAS_CARDIO, HAS_WEIGHTS, HAS_POOL
recFinal@data$has_cardio <- pmax(recFinal@data$FACILITIES_Aerobics, recFinal@data$FACILITIES_Cardio.Eqpmnt, recFinal@data$FACILITIES_Cardio.Eqpmt)

recFinal@data$has_weights <- recFinal@data$FACILITIES_Weight.Room

recFinal@data$has_pool <- pmax(recFinal@data$FACILITIES_Pool..Indoor., recFinal@data$FACILITIES_Pool..Outdoor.,recFinal@data$FACILITIES_Indoor.Kiddie.Pool)

recFinal@data$has_gym <- pmax(recFinal@data$FACILITIES_Gym..Large., recFinal@data$FACILITIES_Gym..Reg..Size.,recFinal@data$FACILITIES_Gym..Small.)

# Delete unnecessary columns
recFinal@data[,8:35] <- NULL
```

Similarly, split up the program categories into separate, binary columns.

```{r}
# Turn each facility type into a column
recFinal <- cSplit_e(recFinal, "PROGRAMS", sep = ",", mode = "binary",
         type = "character", fill = 0, drop = TRUE)
colnames(recFinal@data)

# Compute interesting facility distinctions: HAS_CARDIO, HAS_WEIGHTS, HAS_POOL
recFinal@data$has_aquatics <- pmax(recFinal@data$PROGRAMS_Aquatics, recFinal@data$PROGRAMS_Aquatics..using.Wash.Park.Pool.)
recFinal@data[,11:12] <- NULL

# Rename other columns
colnames(recFinal@data)[11:18] <- c("has_arts_culture", "has_day_camps", "has_educ_programs", "has_fitness_health_programs", "has_senior_programs", "has_social_enrich_clubs", "has_special_events", "has_sports")
```

Check out the final product:

```{r}
head(recFinal)
```

All done! We save the result as a csv.

```{r}
SavePointsAsCSV(recFinal, "rec_centers.csv")
```

## Athletic fields

Next, look at athletic fields. Get and preview the data:

```{r, results="hide"}
fields <- GetOpenData("athletic_fields")
```

```{r}
colnames(fields@data)
head(fields@data)
```

Subset to useful variables and rename columns for simplicity.

```{r}
fieldsSmall <- fields[, c('FEATURE', 'LOCATION', 'FIELD_TIER', 'CLASS_CATE')]
colnames(fieldsSmall@data) <- c('sport', 'location', 'tier', 'class')
head(fieldsSmall@data)
```

Save final product as a csv.

```{r}
SavePolygonsAsCSV(fieldsSmall, "fields.csv")
```

## Playgrounds

Next, look at playgrounds. Get and preview the data:

```{r, results="hide"}
playgrounds <- GetOpenData("playgrounds")
```

```{r}
colnames(playgrounds@data)
head(playgrounds@data)
```

Subset to useful variables and rename columns for simplicity.

```{r}
playgroundsSmall <- playgrounds[, c('LOCATION', 'YEAR_REHAB', 'CLASS_CATE')]
colnames(playgroundsSmall@data) <- c('location', 'year_rehab', 'class')
head(playgroundsSmall@data)
```

Save final product as a csv.

```{r}
SavePolygonsAsCSV(playgroundsSmall, "playgrounds.csv")
```

## Parks

```{r}
parks <- GetOpenData("parks")
head(parks@data)

parks = parks[c(2,5,23)]
names(parks) <- c("name","class","facilities")
parks[["name"]] <- as.character(parks[["name"]])

# Split facilities into columns
parks <- SplitCommas(parks, "facilities")

colSums(parks@data[,3:194])



SavePolygonsAsCSV(parks, "parks.csv")
```



## Libraries

A lot of this info is redundant, such as abbreviations, address/state/zip (which is contained in the shapefile metadata). Other info is unnecessary, such as the status (whether under construction, temporary construction, etc). We also will rename the columns to understandable names.

```{r}
libraries <- GetOpenData("libraries")
# only keep relevant 
libraries = libraries[,c(1,9,10,11)]
names(libraries) <- c("name","patron_count","circulation_volume","sqft")
libraries[["name"]] <- as.character(libraries[["name"]])
libraries[["patron_count"]] <- as.numeric(as.character(libraries[["patron_count"]]))
libraries[["circulation_volume"]] <- as.numeric(as.character(libraries[["circulation_volume"]]))
libraries[["sqft"]] <- as.numeric(as.character(libraries[["sqft"]]))

head(libraries)

SavePointsAsCSV(libraries, "libraries.csv")
```


## Licensed Childcare Facilities

Joe has.
