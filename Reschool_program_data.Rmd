---
title: "Reschool_program_data"
output: html_document
---
************************************Blueprintforsummer program data**************************************************************************
```{r}

programdata = read.csv(file = "C:/Users/Sreekanth/Desktop/DSSG Project/programdata.csv", na.strings = "")
head(programdata)
```
Looking at the distinct cities in which the session was conducted. The camp_city seems to be the location of the city where the organization is based out of. 
```{r}
unique(programdata$session_city)
```
I guess there is an issue with leading and trailing spaces. So getting rid of them. 

```{r}
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
programdata$session_city <- trim(programdata$session_city)
unique(programdata$session_city)

```


```{r}
unique(programdata$camp_name)
```

Overall, there seem to be 62 unique programs over the summer. They have different sessions runnung across the summer.

```{r}
programdata[programdata$camp_name == 'Pi Q Math',]
```
Each session seems to have a unique session id. Just verifying if the data is unique at a session id level.Also, the organizations are uniquely identifiable using a camp id. In that case, there should be 62 unique camp ids.

```{r}
nrow(programdata)
length(programdata$session_id)
length(unique(programdata[,1]))
```

Looks like it. 

Lets obtain the distinct session addresses. 
```{r}
unique(programdata$session_address_1)
```

I am going to remove the trailing and ending whitespcases and '.'s 
```{r}
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
programdata$session_address_1 <- trim(programdata$session_address_1)
programdata$session_city <- trim(programdata$session_city)
programdata$session_zip <- trim(programdata$session_zip)
programdata$session_address_1 =   gsub("\\.$", " ", programdata$session_address_1)
```

There are two addresses that have NA values. But they have an other zipcode associated with it as well. We will use fill from dyplyr to fill it with the previous zipcode after sorting it.
```{r}
programdata[which(is.na(programdata$session_zip)), ]
library(tidyr)
programdata <- programdata[order(programdata$session_city, programdata$session_address_1) , ]
programdata = fill(programdata,session_zip )
```

************Getting the unique addresses that needs to be fed into google ALPI********************
I am checking if there are any session addresses that are repeated.
```{r}
camp_address = unique(programdata[c("session_address_1",  "session_city", "session_zip")])
camp_address = camp_address[order(camp_address$session_address_1) , ]
length(camp_address$session_address_1)
length(unique(camp_address$session_address_1))
```
There are three duplicates. 
```{r}
camp_address[duplicated(camp_address$session_address_1)|duplicated(camp_address$session_address_1, fromLast=TRUE),]
```
Okay, there is the issue of duplicates beacuse of the presence of different zipcodes for three different session addresses in the city of Aurora.
On doing a google search, 2390 Havana St should have the zipcode 80010, 3054 S Laredo St has the zip code 80013and 800 Telluride St has the zipcode 80011

```{r}

for (i in 2:nrow(camp_address)){

  if(camp_address[i,1] == camp_address[i-1,1]){
    a = a+1
    camp_address[i,3] = camp_address[i-1,3]
  }
}
camp_address = unique(camp_address[c("session_address_1",  "session_city", "session_zip")])
length(camp_address$session_address_1)
length(unique(camp_address$session_address_1))
```

Get them all in one column
```{r}

cols <- c( 'session_address_1' , 'session_city' , 'session_zip' )
camp_address$complete_session_address <- apply( camp_address[ , cols ] , 1 , paste , collapse = ", " )
nrow(camp_address)
head(camp_address)
```




```{r}
geocodeAddress <- function(address) {
  require(RJSONIO)
  full <- paste(address)
  url <- "https://maps.google.com/maps/api/geocode/json?address="
  url <- URLencode(paste(url, full, '&sensor=false&key=','AIzaSyAHW3TJFoPOIqXl9-lu4Wz928vu38kUCxE', sep = ""))
  x <- fromJSON(url, simplify = FALSE)
  if (x$status == "OK") {
    
      out <- c(x$results[[1]]$geometry$location$lat,
               x$results[[1]]$geometry$location$lng)
    } else {
      out <- NA
  }
  Sys.sleep(0.05)  # API only allows 50 requests per second
  out
}


#Initialize
camp_address$LAT<-NA
camp_address$LON<-NA
g_add=list()

old <- Sys.time() # get start time
for (i in 1:nrow(camp_address)) {
  g_add <- geocodeAddress(camp_address$complete_session_address[i])
  camp_address$LAT[i] <- g_add[1]
  camp_address$LON[i] <- g_add[2]

  if (i == nrow(camp_address)) cat("Done!\n")
}
new <- Sys.time() - old # calculate difference
print(new)

camp_address

```

```{r}
#Joining it back with the main dataset
camp_address_intermediate = camp_address[,c("session_address_1","complete_session_address","LAT","LON")]
programdata_final = merge(x = programdata, y = camp_address_intermediate, by = "session_address_1", all = TRUE)

programdata_final =  programdata_final[, !names(programdata_final) %in% c("camp_youtube","camp_phone","camp_facebook",
                                                                          "camp_twitter", "ï..camp_id")] 

#Splitting the session_categories into different columns
programdata_final <- cSplit_e(programdata_final, "session_categories", sep=",", mode = "binary",
        type = "character", fill = 0, drop = TRUE)

#Converting all column names into small case
dbSafeNames = function(names) {
  names = gsub('[^a-z0-9]+','_',tolower(names))
  names = make.names(names, unique=TRUE, allow_=TRUE)
  names = gsub('.','_',names, fixed=TRUE)
  names
}
colnames(programdata_final) = dbSafeNames(colnames(programdata_final))

#Extracting the column names to fill it in the codebook
column_names = colnames(programdata_final)
column_names_dataframe = data.frame(row.names = column_names)
write.csv(column_names_dataframe, file = "programdata_columnnames.csv")


```



```{r}
head(programdata_final)
unique(programdata_final$session_categories)
```


************************Working on the main program dataset to extract the program type into sepearte columns***************

```{r}
library(splitstackshape)
programdata1 = cSplit(programdata, "session_categories", sep=",")

programdata1 <- cSplit_e(programdata, "session_categories", sep=",", mode = "binary",
        type = "character", fill = 0, drop = TRUE)


head(programdata1)
names(programdata1)
```

**********************************Howen's regex problem*******************************************
```{r}

censusage = read.csv(file = "C:/Users/Sreekanth/Desktop/DSSG Project/CensusAge.csv", na.strings = "")

#Extracting the names of the columns that need to be modified
column_names = colnames(censusage)[6:28]

#Extracting the appropriate string to name the modified columns
modified_column_name = sapply(1:length(column_names), function(x) sub(".*Male....", "", column_names[x]))

#Adding the columns that are necessary and giving them appropriate column names 
added_columns = cbind(censusage[,6:28] + cbind(censusage[,29:51]))
added_columns = as.data.frame(added_columns)
colnames(added_columns) = modified_column_name

#Delete the columns not required and adding the modified columns to the main censusage dataset
censusage_final = censusage[-c(6:51)]
censusage_final = cbind(censusage_final,added_columns)

```


```{r}
censusage[c(6,7,8,29,30,31)]
```
**********************************Howen's race dataset problem*******************************************
```{r}
race = read.csv(file = "C:/Users/Sreekanth/Desktop/DSSG Project/race.csv", na.strings = "")

#Extracting the names of the columns that need to be modified
column_names = colnames(race)[6:14]

#Extracting and manupulating the appropriate string to name the modified columns
modified_column_name1 = sapply(1:length(column_names), function(x) gsub(".*Total....", "", column_names[x]))
modified_column_name = sapply(1:length(modified_column_name1), function(x) paste0("Perecentage ", modified_column_name1[x]))

#Obtaining the percentages
additional_columns = (race[,6:14]/race[,5])*100

#Renaming the column names
additional_columns = as.data.frame(additional_columns)
colnames(additional_columns) = modified_column_name

#Delete the columns not required and adding the modified columns to the main censusage dataset
race_final = cbind(race, additional_columns)
```


**************************Howen's language dataset problem********************************************************
```{r}
languagedata = read.csv(file = "C:/Users/Sreekanth/Desktop/DSSG Project/languagedata.csv", skip = 1, na.strings = "")

#Selecting only the 'estimate' columns and deleting all the 'margin of erro'r columns
languagedata <- languagedata[,c(1,2,3,4,seq(50,ncol(languagedata),2))]

#Selecting only the 'estimate' columns and deleting all the 'margin of erro'r columns
languagedata_1 <- languagedata[,-c(1:7,12, 17, 22, 27:29, 34, 39, 44)]
languagedata_2 <- languagedata[, c(1:7,12, 17, 22, 27:29, 34, 39, 44)]

modified_columns = cbind(languagedata_1[c(seq(1,31,2))] + languagedata_1[c(seq(2,32,2))])

languagedata_final = cbind(languagedata_2, modified_columns)

#Making the column names much better
library(magrittr)

x = colnames(languagedata_final)
x %<>% gsub("Estimate..", "", .) %>% gsub(".years....", "", .) %>% gsub("over....", "", .) %>% gsub("Speak", "", .)

#Assigning the column names
colnames(languagedata_final) = x

write.csv(languagedata_final, file = "languagedata_final.csv")
```



******************************Denver museum data*************************************************************************
```{r}

museumdata = read.csv(file = "C:/Users/Sreekanth/Desktop/DSSG Project/museum_locations.csv",  na.strings = "")

#Get the lat and long using google API
geocodeAddress <- function(address) {
  require(RJSONIO)
  full <- paste(address)
  url <- "https://maps.google.com/maps/api/geocode/json?address="
  url <- URLencode(paste(url, full, '&sensor=false&key=','AIzaSyAHW3TJFoPOIqXl9-lu4Wz928vu38kUCxE', sep = ""))
  x <- fromJSON(url, simplify = FALSE)
  if (x$status == "OK") {
    
      out <- c(x$results[[1]]$geometry$location$lat,
               x$results[[1]]$geometry$location$lng)
    } else {
      out <- NA
  }
  Sys.sleep(0.05)  # API only allows 50 requests per second
  out
}


#Initialize
g_add=list()

old <- Sys.time() # get start time
for (i in 1:nrow(museumdata)) {
  g_add <- geocodeAddress(museumdata$address[i])
  museumdata$lat[i] <- g_add[1]
  museumdata$long[i] <- g_add[2]

  if (i == nrow(museumdata)) cat("Done!\n")
}
new <- Sys.time() - old # calculate difference
print(new)

museumdata_final = museumdata


```


