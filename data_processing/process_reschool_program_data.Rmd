---
title: "Process reschool program data"
output: html_document
---

Load libraries we will need:

```{r}
library(tidyr)
library(splitstackshape)  # for splitting the categories column
# library(RJSONIO)  # for Jose's geocoding
library(ggmap)
library(rgdal)
library(rgeos)
```

## Blueprint4summer program data

Read in the Blueprint4Summer program data from a local csv.

```{r}
programdata = read.csv(file = "/Users/kelliemacphee/Desktop/dssg2018/Data/Blueprint4Summer.csv", na.strings = "")
```

Fix the types of the columns so that everything is loaded properly into the database later. Do this first thing in case any other code below might be affected, too.

```{r}
integer_cols <- c("camp_id", "session_id", "camp_zip", "session_size", 
                  "session_min_age", "session_max_age", "session_cost", "session_count", 
                  "session_zip")

char_cols <- c("camp_tag", "camp_name", "camp_website", "camp_email", "camp_phone", 
               "camp_address_1", "camp_address_2", "camp_city", "camp_state", "camp_facebook", 
               "camp_twitter", "camp_youtube", "camp_short_description", 
               "camp_long_description", "session_name", "session_short_description", 
               "session_long_description", "session_reg_open", "session_reg_close", 
               "session_gender", "session_date_start", "session_date_end",
               "session_address_name", "session_address_1", "session_address_2",
               "session_city", "session_state", "session_categories")

for (col in integer_cols) {
  programdata[[col]] <- as.integer(programdata[[col]])
}

for (col in char_cols) {
  programdata[[col]] <- as.character(programdata[[col]])
}

head(programdata)
```

First we look at the distinct cities in which the sessions were conducted. The camp_city seems to be the location of the city where the organization is based out of. 

```{r}
unique(programdata$session_city)
```

I guess there is an issue with leading and trailing spaces. So getting rid of them. 

```{r}
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
programdata$session_city <- trim(programdata$session_city)
unique(programdata$session_city)
```

Now we look at the different camps/organizations.

```{r}
unique(programdata$camp_name)
```

Overall, there seem to be 62 unique programs over the summer. They have different sessions running across the summer. As an example:

```{r}
programdata[programdata$camp_name == 'Pi Q Math',]
```

Each session seems to have a unique session id. Next we just verify if the data is unique at a session id level. Also, check if the organizations are uniquely identifiable using a camp id. In that case, there should be 62 unique camp ids.

```{r}
nrow(programdata)
length(programdata$session_id)
length(unique(programdata[,1]))
```

Looks like it. Lets obtain the distinct session addresses. 

```{r}
unique(programdata$session_address_1)
```

I am going to remove the trailing and ending whitespcases and '.'s 

```{r}
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
programdata$session_address_1 <- trim(programdata$session_address_1)
programdata$session_city <- trim(programdata$session_city)
# programdata$session_zip <- trim(programdata$session_zip)
programdata$session_address_1 =   gsub("\\.$", " ", programdata$session_address_1)
```

There are two addresses that have NA values. But they have another zipcode associated with it as well. We will use fill from dyplyr to fill it with the previous zipcode after sorting it.

```{r}
sum(is.na(programdata$session_reg_open))  # 1905
sum(is.na(programdata$session_reg_close))  # 1370

#programdata[which(is.na(programdata$session_zip)), ]
programdata <- programdata[order(programdata$session_city, programdata$session_address_1) , ]

#checking if we're introducing new na's or just reordering
sum(is.na(programdata$session_reg_open))  # 1905
sum(is.na(programdata$session_reg_close))  # 1370

programdata = fill(programdata, session_zip)
```

There are also some xa0's (no-break spaces) at the beginning of a couple of addresses. Remove these, so that we can geocode properly and query the database properly.
```{r}
programdata$session_address_1 <- gsub('*\xa0', '', programdata$session_address_1)
```

## Getting the unique addresses that need to be fed into google API

I am checking if there are any session addresses that are repeated.

```{r}
camp_address = unique(programdata[c("session_address_1",  "session_city", "session_state", "session_zip")])
camp_address = camp_address[order(camp_address$session_address_1) , ]
length(camp_address$session_address_1)
length(unique(camp_address$session_address_1))
```

There are three duplicates:

```{r}
camp_address[duplicated(camp_address$session_address_1)|duplicated(camp_address$session_address_1, fromLast=TRUE),]
```

Okay, there is the issue of duplicates beacuse of the presence of different zipcodes for three different session addresses in the city of Aurora.
On doing a google search, 2390 Havana St should have the zipcode 80010, 3054 S Laredo St has the zip code 80013 and 800 Telluride St has the zipcode 80011. Manually replace these.

```{r}
for (i in 2:nrow(camp_address)){
  if(camp_address[i,1] == camp_address[i-1,1]){
    camp_address[i,3] = camp_address[i-1,3]
  }
}

camp_address = unique(camp_address[c("session_address_1",  "session_city", "session_state", "session_zip")])
# length(camp_address$session_address_1)
# length(unique(camp_address$session_address_1))
head(camp_address)
```

Get all the pieces of the session address in one column.

```{r}
#cols <- c('session_address_1' , 'session_city' , 'session_zip' )
# camp_address$complete_session_address <- apply(camp_address[ , cols ], 1, paste, collapse = ", ")
camp_address$complete_session_address <- paste(camp_address$session_address_1, camp_address$session_city, "CO", camp_address$session_zip)

nrow(camp_address)
head(camp_address)
```

Now we move on to geocoding the addresses so that we have lat/long coordinates.

```{r}
# Function for Jose's way of geocoding
# geocodeAddress <- function(address) {
#   full <- paste(address)
#   url <- "https://maps.google.com/maps/api/geocode/json?address="
#   url <- URLencode(paste(url, full, '&sensor=false&key=','AIzaSyAHW3TJFoPOIqXl9-lu4Wz928vu38kUCxE', sep = ""))
#   x <- fromJSON(url, simplify = FALSE)
#   if (x$status == "OK") {
#     
#       out <- c(x$results[[1]]$geometry$location$lat,
#                x$results[[1]]$geometry$location$lng)
#     } else {
#       out <- NA
#   }
#   Sys.sleep(0.05)  # API only allows 50 requests per second
#   out
# }

# Initialize the lat/longs to NAs
camp_address$long <- NA
camp_address$lat <- NA
# g_add <- list()  # Jose's way

# Run the geocoding!
max_runs <- 5  # sometimes don't get the lat/long on the first run - try again

for (k in 1:max_runs) {
  notGeocoded <- which( is.na(camp_address$lat) | is.na(camp_address$long) )
  for (i in notGeocoded) {
    # geocode this row - Joe's way
    result <- geocode(camp_address$complete_session_address[i], output="latlona", source="google")
    camp_address$long[i] <- as.numeric(result[1])
    camp_address$lat[i] <- as.numeric(result[2])
    
    Sys.sleep(0.1)  # prevent over 50 google maps queries per second
    
    # Jose's way
    # g_add <- geocodeAddress(camp_address$complete_session_address[i])
    # camp_address$lat[i] <- g_add[1]
    # camp_address$long[i] <- g_add[2]
  }
}
```

Join the geocodings back with the main dataset.

```{r}
# Join geocodings and drop redundant address columns
camp_address_intermediate <- camp_address[,c("session_address_1","session_city", "session_state", "session_zip", "lat","long")]

programdata_final <- merge(x = programdata, y = camp_address_intermediate, sort=FALSE)
head(programdata_final)
nrow(programdata_final)  # should be 3136
ncol(programdata_final)  # should be 37 + 2 (adding lat, long)
```

Drop unuseful columns.

```{r}
# Note that camp_tag seems to all be region=co,
# and session_count seems to be all 1's.
colsToDrop <- c("camp_youtube","camp_phone","camp_facebook", "camp_email", "camp_website", "camp_twitter", "?..camp_id", "camp_tag", "session_count")

programdata_final =  programdata_final[, !names(programdata_final) %in% colsToDrop] 

head(programdata_final)
```

Remove times (which are all 00:00:00) from dates.

```{r}
# Reformatting dates (no need for times)
programdata_final$session_date_start = gsub(' 00:00:00','', programdata_final$session_date_start)
programdata_final$session_date_end = gsub(' 00:00:00','', programdata_final$session_date_end)

head(programdata_final)
```

Split the session categories into different columns, and update column names to be simple and database-safe.

```{r}
# Splitting the session_categories into different columns
programdata_final <- cSplit_e(programdata_final, "session_categories", sep=",", mode = "binary",
        type = "character", fill = 0, drop = TRUE)
# Change 0/1 encoding to true/false in the new split columns
newCols <- grep("session_categories", colnames(programdata_final))
for (colnum in newCols) {
  programdata_final[,colnum] <- as.logical(programdata_final[,colnum])
}


# Converting all column names into small case
dbSafeNames = function(names) {
  names = gsub('[^a-z0-9]+','_',tolower(names))
  names = make.names(names, unique=TRUE, allow_=TRUE)
  names = gsub('.','_',names, fixed=TRUE)
  names
}
colnames(programdata_final) = dbSafeNames(colnames(programdata_final))

# Simplifying some column names, to be consistent with rest of database
for (x in c("academic", "arts", "cooking", "dance", "drama", "music", "nature", "sports", "stem")) {
  oldName <- paste("session_categories_", x, sep="")
  newName <- paste("has_", x, sep="")
  colnames(programdata_final)[colnames(programdata_final) == oldName] <- newName
}
colnames(programdata_final)[colnames(programdata_final) == "session_categories_scholarshipsavailable"] <- "has_scholarships"
colnames(programdata_final)[colnames(programdata_final) == "session_categories_offersbeforeaftercare"] <- "has_before_after_care"
colnames(programdata_final)[colnames(programdata_final) == "session_categories_specialneedsstudent"] <- "has_special_needs_offerings"

# move session_address_1 to a better location
programdata_final <- programdata_final[,c(2:24, 1, 25:length(programdata_final))]

head(programdata_final)
colnames(programdata_final)
```

We also want to add the block group ids to the dataset, in addition to the lat/longs.
```{r}
# get block group polygons
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
mypath <- getwd()
dataPath <- file.path(dirname(mypath), "data", "census_clean", "shape_census")
blockGroups <- readOGR(dsn = dataPath, 'shape_census')

# figure out which block group each program is in
coords <- data.frame(programdata_final$long, programdata_final$lat)
coords <- unique(coords)
colnames(coords) <- c("long", "lat")
spatialReschool <- SpatialPoints(coords, proj4string = CRS(proj4string(blockGroups)))
nests <- gIntersects(spatialReschool, blockGroups, byid = TRUE)  # rows=bgroups, cols=programs

# each program should be in at most one block group!! check:
print(paste( sum(colSums(nests) > 1), "errors" ))

true_idxs <- which(nests==TRUE, arr.ind=TRUE)  # col1 = bgroup idx, col2 = program idx
bgroup_idxs  <- true_idxs[,1]
program_idxs <- true_idxs[,2]

reschool_bgs <- data.frame(coords[program_idxs,],
                      blockGroups$Id2[bgroup_idxs]
                      )
colnames(reschool_bgs) <- c("long", "lat", "bgroup_id2")

# strip leading 0's in block group ids
reschool_bgs$bgroup_id2 <- as.character(as.numeric(as.character(reschool_bgs$bgroup_id2))) 
head(reschool_bgs)

programdata_final_bgs <- merge(programdata_final, reschool_bgs, by.x=c("lat", "long"), by.y=c("lat", "long"), all.x=TRUE, all.y=FALSE)
head(programdata_final_bgs)
```

Save the final, clean data to a csv.

```{r}
filename <- paste("clean-reschool-data-", Sys.Date(), ".csv", sep="")
write.csv(programdata_final_bgs, file = filename, row.names = FALSE)
```

Extract and save the column names to fill in the codebook.

```{r}
#Extracting the column names to fill it in the codebook
column_names = colnames(programdata_final)
column_names_dataframe = data.frame(row.names = column_names)
write.csv(column_names_dataframe, file = "/Users/kelliemacphee/Desktop/dssg2018/programdata_columnnames.csv")
```