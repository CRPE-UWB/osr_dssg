---
title: "Denver Open Data Processing - Demographic(ish) Information"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Uncomment the line below if you're using RStudio (NOT KNITR) to run the file
# Makes sure data files are saved in same location as this file,
# and GetOpenData works properly.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

Load the necessary libraries. 

```{r libs, message=FALSE, results="hide"}
library(tidyverse)
library(rgdal)  # for working with spatial data frames
library(rgeos)  # for working with spatial data frames
library(splitstackshape)  # for splitting strings and turning into binary columns
library(gsheet)  # only needed for the afterschool programs, to merge with annotated data
library(ggmap)  # use for geocoding hate crime data

source('open_data_functions.R')  # our functions
```

Now we're ready to get into the data!

## Crime

First we look at crime.

```{r, results="hide"}
crime <- GetOpenData("crime")
```

```{r}
head(crime@data)

# ~200 of the ~400,000 crime locations have 0 as one or both of the coordinates, so we remove those.
crimeSmall <- crime[abs(crime@coords[,1])>.01 & abs(crime@coords[,2])>.01,]

# Subset the data
crimeSmall <- crime[c(3,5,6,18,19)]
names(crimeSmall) <- c("offense_code","type","category","is_crime","is_traffic")

crimeFinal <- crimeSmall
head(crimeFinal)
```

## Hate Crimes

Next we look at hate crimes.

```{r, results="hide"}
url <- "https://www.denvergov.org/media/gis/DataCatalog/hate_crimes/BiasMotivatedCrimes.csv"
MakeDir("raw_data")  # make a raw data directory, if one doesn't exist yet
file <- file.path("raw_data", basename(url))
download.file(url, file)
hate <- read.csv(file)
```

Look at and subset data.

```{r}
head(hate)

hateSmall <- hate[,c(2,4,7,8,10,11)]
names(hateSmall) <- c("date","case_status","description","bias_type","location_description","address")
hateSmall$date <- as.Date(gsub(" .*","",hateSmall$date),"%m/%d/%Y")
```

We have to geocode these addresses, which themselves are already deidentified. Note that this may take around 1-10 minutes.

```{r, results="hide"}
hateSmall$addressFull <- paste(hateSmall$address, "denver", "colorado", sep=", ")

for(i in 1:nrow(hateSmall)) {
  result <- geocode(hateSmall$addressFull[i], output="latlona", source="google")
  hateSmall$long[i] <- as.numeric(result[1])
  hateSmall$lat[i] <- as.numeric(result[2])
  Sys.sleep(1)
}

hateSmall$addressFull <- NULL
hateFinal <- hateSmall

head(hateFinal)
```

## Foreclosures

Next we look at foreclosures.

```{r, results="hide"}
foreclosures <- GetOpenData("foreclosures")
```

```{r}
head(foreclosures)

# Subset and clean data
foreclosuresFinal = foreclosures[c(4)]
names(foreclosuresFinal) = c("year")
foreclosuresFinal[["year"]]=as.numeric(as.character(foreclosuresFinal[["year"]]))
```

## Police Shootings

Next we look at police shootings.

```{r, results="hide"}
polShoot <- GetOpenData("denver_police_officer_involved_shootings")
```

```{r}
head(polShoot)

# one super big entry for no reason - delete this
polShoot <- polShoot[abs(polShoot@coords[,1])<1000 & abs(polShoot@coords[,2])<1000,]

# Subset the data
polShootFinal <- polShoot[c(5,6,10,15,16,17,18,19,20,21)]
names(polShootFinal) <- c("initiated_by","contact_basis","person_role","gender","age","race","ethnicity","armed_with","discharged_firearm","casualty_status")
polShootFinal[["age"]] <- as.numeric(as.character(polShootFinal[["age"]]))

head(polShootFinal)
```

## Police Stations

Next we look at police stations.

```{r, results="hide"}
polStations <- GetOpenData("police_stations")
```

```{r}
head(polStations)

# Subset and clean the data
polStationsFinal = polStations[,c(1,3,12,13,15)]
names(polStationsFinal) = c("id","name","district","type","is_publicly_accessible")
polStationsFinal[["name"]]=as.character(polStationsFinal[["name"]])

head(polStationsFinal)
```

## Save all the files to csvs

```{r}
SavePointsAsCSV(crimeFinal, "crimes.csv")
write.csv(hateFinal, file=file.path("clean_data","hate_crimes.csv"), na="", row.names=FALSE)
SavePointsAsCSV(foreclosuresFinal, "foreclosures.csv")
SavePointsAsCSV(polShootFinal, "police_shootings.csv")
SavePointsAsCSV(polStationsFinal, "police_stations.csv")
```

## Make the codebook

Build the codebook, i.e. get variable names for each csv saved above in clean_data. Store the results in a dataframe.

```{r}
filenameList <- c("crimes.csv","hate_crimes.csv","foreclosures.csv","police_shootings.csv","police_stations.csv")

maxVars <- 50
codebook <- data.frame(matrix(nrow=maxVars, ncol=0))

for (filename in filenameList) {
  # load csv into workspace
  file <- read.csv(file.path("clean_data",filename) )
  
  vars <- rep(NA, maxVars)
  vars[1:length(names(file))] <- names(file)
  
  # save column names to dataframe
  codebook[[filename]] <- vars
}

write.csv(codebook, file=file.path("clean_data","codebook_demographic.csv"), row.names=FALSE)
```

```{r}
# Function to get list of column names in a data frame
#    input:   data frame
#    output:  single string of column names, separated by commas
GetVars <- function(df) {
  toString(names(df))
}

# Function to get codes from a particular column in a data frame
#    input:   data frame, column name (string)
#    output:  list of codes used in that column
GetCodes <- function(df, colName) {
  vals <- sort(unique(df[[colName]]))
  print(vals)
}
```
