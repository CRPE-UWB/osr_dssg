---
title: "Google Analytics API"
author: "Andrew Taylor"
date: "6/29/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###API Codebook

Metrics and Dimensions codebook: https://developers.google.com/analytics/devguides/reporting/core/dimsmets

###Packedge we be using
```{r}
library(googleAnalyticsR)
```

###Authenticate
#VERY IMPORTANT:
The "ga_auth()" command will prompt an internet dialogue to authenticate our access to google analytics. In this case, let's use the DSSG OSR one. You have to use the browser for this, at least with this packege. 
```{r}
##Authenticate
ga_auth()

##Get accounts
account_list <- ga_account_list()

##Every account has a view ID
account_list$viewId

##Here we extract the view ID we want. One seems to be the homepage and two seems to be the search engine?
ga_id_one <- account_list$viewId[1]
ga_id_two <- account_list$viewId[2]
```


###Pulling Path Level Data
```{r}
#works
PathLevel <- google_analytics(
  ga_id_two, 
  date_range=c("2018-01-01",(todays_date)),
  metrics=c('Users','timeOnPage','pageviews','pageviewsPersession','uniquePageviews'),
  dimensions =c('Latitude','Longitude',"PagePath",'SecondPagePath',"pageTitle"),max=50000)
```

###Parsing Search Path Function
This function turns our html string into something we can split systematically
```{r}
ParsePath <- function(htmlString) {
  htmlString <-(gsub("<.*?>", "", htmlString))
  htmlString <- (gsub("/search","",htmlString))
  htmlString <- (gsub("&",",",htmlString))
  htmlString <- (gsub("?","",htmlString))
  htmlString <- (gsub("/?","",htmlString))
  htmlString <- (gsub("selected","",htmlString))
  return(htmlString)
}
```

###Creating recognition functions
These functions read the full parsed html string, determine the feature, and then return the split version of the url.
```{r}
ReturnTime <- function(x){
  check <- grepl("sessionTimes",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("sessionTimes",stringcheck[i])
      if (check.i==TRUE){
        print(stringcheck[i])}
    }}}

ReturnMaxCost <- function(x){
  check <- grepl("maximumCost",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("maximumCost",stringcheck[i])
      if (check.i==TRUE){
        print(stringcheck[i])}
    }}}

ReturnMinCost <- function(x){
  check <- grepl("minimumCost",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("minimumCost",stringcheck[i])
      if (check.i==TRUE){
        print(stringcheck[i])}
    }}}

ReturnDistance <- function(x){
  check <- grepl("distance",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("distance",stringcheck[i])
      if (check.i==TRUE){
        print(stringcheck[i])}
    }}}

ReturnCategory <- function(x){
  check <- grepl("Categories",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("Categories",stringcheck[i])
      if (check.i==TRUE){
        print(stringcheck[i])}
    }}}

ReturnGender <- function(x){
  check <- grepl("gender",x)
  if(check==TRUE){
    stringcheck <- str_split_fixed(x,",",Inf)
    for (i in 1:(length(stringcheck))){
      check.i <- grepl("gender",stringcheck[i])
      if (check.i==TRUE){
        return(stringcheck[i])}
    }}}
```

###Applying them functions
Using our functions to fill out categories
```{r}
PathLevel$CleanPath <- ParsePath(PathLevel$PagePath)
PathLevel$gender <- sapply(PathLevel$CleanPath,ReturnGender)
PathLevel$distance <- sapply(PathLevel$CleanPath,ReturnDistance)
PathLevel$category <- sapply(PathLevel$CleanPath,ReturnCategory)
PathLevel$mincost <- sapply(PathLevel$CleanPath,ReturnMinCost)
PathLevel$maxcost <- sapply(PathLevel$CleanPath,ReturnMaxCost)
PathLevel$sessiontimes <- sapply(PathLevel$Clean,ReturnTime)
```

###Cleaning Functions
Now that we've returned the split version of the html string, we need to clean it up so that only the relevant information is included. 
```{r}
CleanHash<- function(x){
  stringcheck <- str_split_fixed(x,"=",Inf)
  ifelse(length(stringcheck)>1,return(stringcheck[2]),"")
}
```

###Cleaning
```{r}
PathLevel$gender <- sapply(PathLevel$gender,CleanHash)
PathLevel$distance <-sapply(PathLevel$distance,CleanHash)
PathLevel$category <- sapply(PathLevel$category,CleanHash)
PathLevel$mincost <- sapply(PathLevel$mincost,CleanHash)
PathLevel$maxcost <- sapply(PathLevel$maxcost,CleanHash)
PathLevel$sessiontimes <- sapply(PathLevel$sessiontimes,CleanHash)
```

###Aggregating Users By Category & Lat/Lon
While we may have started our report with several different metrics, here we're only interested in the number of users searching for "x" features at "y" lat/lon. 
```{r}
Search_Summary  <- aggregate(Users ~ gender+distance+category+mincost+maxcost+sessiontimes+Latitude+Longitude,PathLevel,sum)
colnames(Search_Summary) <- c("gender","distance","category","mincost","maxcost","sessiontimes","Lat","Long","Users") #updating colnames
GoogleSearchData <- Search_Summary #making final name
```

