---
title: "Yelp Data Denver"
author: "Andrew Taylor"
date: "6/27/2018"
output: html_document
---
###Using Yelp API
While not relevant to this project, it may be nice to a have a quick review on how to use the Yelp API. Unfortunatley, at the time of this markdown the Yelp API only applies to resturants with specific delivery service through Yelp, and thus is not helpful for locating out of scool resources.

For information on the yelp key used in this analysis see the Yelp key markdown (not shared over github).

###Load required libraries
```{r echo=FALSE}
library(tidyverse)
library(httr)
```

###Building url for query
This is the base code for building a url to query the yelp api. The limit max = 50 results saved per query, max = 1,000 total per query. We create a workaround in the loop at the end.
```{r}
yelp <- "https://api.yelp.com"
categories <- NULL
limit <- 50
location <- "Denver, CO"
radius <- 8000
url <- modify_url(yelp, path =c('v3','businesses','search'),
                  query = list(location = location, limit = limit, offset=1000,radius = radius))
res <- GET(url, add_headers('Authorization' = paste('bearer',yelp_api_key)))
results <- content(res)
```

###Function for parsing yelp html with example
```{r}
yelp_httr_parse <- function(x){

  parse_list <- list(id = x$id, 
                     name = x$name, 
                     rating = x$rating, 
                     review_count = x$review_count, 
                     latitude = x$coordinates$latitude, 
                     longitude = x$coordinates$longitude, 
                     address1 = x$location$address1, 
                     city = x$location$city, 
                     state = x$location$state, 
                     distance = x$distance)
  
  parse_list <- lapply(parse_list, FUN = function(x) ifelse(is.null(x), "", x))
  
  df <- data_frame(id=parse_list$id,
                   name=parse_list$name, 
                   rating = parse_list$rating, 
                   review_count = parse_list$review_count, 
                   latitude=parse_list$latitude, 
                   longitude = parse_list$longitude, 
                   address1 = parse_list$address1, 
                   city = parse_list$city, 
                   state = parse_list$state, 
                   distance= parse_list$distance)
  df
}

results_list <- lapply(results$businesses, FUN = yelp_httr_parse)

payload_100 <- do.call("rbind", results_list)
```

###Looping to get around yelp's limits
There are two reasons we need to use the much despised for loop here. 

1.) Yelp limits the number of results we can collect to 50 per search, and-

2.) Yelp limits the max number of results per search we analyze to 999. This means that for the ~3700 businesses on yelp in denver, even if we collect 50 at a time, we can't go over 1,000. To get around this, we search by zip code, max out the zip code to 1,000 queries, collect them 50 at time, repeat. 
```{r}
yelp_results <- data.frame()
denver_zipcodes <- c(80012, 80014, 80110, 80111, 80123, 80202, 80203, 80204, 80205, 80206, 80207, 80209, 80210, 80211, 80212, 80214, 80216, 80218, 80219, 80220, 80221, 80222, 80223, 80224, 80226, 80227, 80230, 80231, 80232, 80235, 80236, 80237, 80238, 80239, 80246, 80247, 80249, 80264, 80290, 80293, 80294)

for (i in 1:(length(denver_zipcodes))){
  zip <- denver_zipcodes[i]
  for (z in 1:19){ #here we start the secondary loop reading search results, 50 at a time, per zip code.
  offset <- (1+z)*50 #here our offset is increased by 50 per loop. 
  yelp <- "https://api.yelp.com"
  categories <- NULL #this is null because we do not know which categories a OSR will be in
  limit <- 50 #this is the max limit
  location <- paste("Denver, CO",zip) #here we paste the zip code in to search by zip
  radius <- 8000
  url <- modify_url(yelp, path =c('v3','businesses','search'),
                  query = list(location = location, limit = limit, offset=offset,radius = radius))
  res <- GET(url, add_headers('Authorization' = paste('bearer',yelp_api_key))) #here we enter our api key for authentication with results
  results <- content(res) #this is a httr function for pre-parsing
  results_list <- lapply(results$businesses, FUN = yelp_httr_parse) #here we use the httr yelp function for parsing the yelp results
  payload.i <- do.call("rbind", results_list) #here we transfer the parsed results in a dataframe
  yelp_results <- rbind(yelp_results,payload.i) #here we compile results of every search into one dataframe
  print(paste("we're totally not exceeding query limits",i,z))}
  Sys.sleep(0.01) #there is a limit on queries per second, so better safe than sorry with a small pause here
}
```

###Cleaning total results for Denver
Because we searched within miles of each zip, rather than from the city center of denver, we got quite a few businsses located in adjacent cities. Here we remove the few duplicate records, remove noise & subset for Denver. 
```{r}
yelp_reviews <- unique(yelp_results) #remove initial duplicates
yelp_reviews <- yelp_reviews[-c(1)] #remove yelp ID
yelp_reviews <- unique(yelp_reviews) #remove duplicates post yelp ID

denver_cities <- c("Denver","Denver Central East","Denver Central West","Denver Southest","Denver Southwest") #create list to subset
denver_reviews <- yelp_reviews[yelp_reviews$city %in% denver_cities,] #subset by list
```

