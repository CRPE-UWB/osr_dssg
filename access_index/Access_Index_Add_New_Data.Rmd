---
title: "Access_Index_Add_New_Data"
author: "Andrew Taylor"
date: "8/13/2018"
output: html_document
---

##Intro
This markdown defines how to add new to program data to the access index so it can continue to be used for future analysis. This assumes that new programs will be not uniquely identified, and instead the user will read a new export of blueprint for summer data, with the same formatting as the data originally used in this project. To add new data under this assumption, we complete the following steps: 

1.) Read required data (new and old) 
2.) Match & merge new data to old block group distances 
3.) For programs with new addresses, find new travel times for all block groups 
4.) Calculate the access index for new session addressess. 

Note that so long as we call the access index from the new data, we will automatically subset our dataframe of travel times to the addresses in that dataframe, per the specifications of the user, so addresses which have been removed should not be double counted. 

Even simpler, the input for this markdown is a new CSV of summer programs and a google API key for calculating distances from newly added programs to block group centers. The output is a new table of access indices, which are used in the RShiny app. 

###Insert your inputs
```{r}
# First read in the new file of programs
# replace "example_new_program_list.csv" with your own filename below, or try out this example to see how it works
new_reschool_programs <- read.csv("../data/shiny_tables/b4s_programs.csv")
#new_reschool_programs <- read.csv("example_new_program_list.csv")
#new_reschool_programs <- new_reschool_programs[,c("session_address_1",test_col)]

# Then put your API key here (keep the quotation marks, just replace YOUR_KEY_HERE with the really long number that is your google api key)
google_api_key <- "YOUR_KEY_HERE"
```

###Get prior data
```{r}
# Previous distances from block centroids to programs
block_distance <- read.csv("../data/shiny_tables/block_distance.csv")

# Previous address of summer programs
reschool_programs <- read.csv("../data/shiny_tables/b4s_programs.csv")
reschool_addresses <- reschool_programs[,c("session_address_1","lat","long")] #subset to what we need
reschool_addresses <- unique(reschool_addresses) #just in case there's any duplicates
rownames(reschool_addresses) <- NULL

driving_index <- read.csv("../data/shiny_tables/access_indices/driving_index.csv")
driving_index_disability <- read.csv("../data/shiny_tables/access_indices/driving_index_disability.csv")
transit_index <- read.csv("../data/shiny_tables/access_indices/transit_index.csv")
transit_index_disability <- read.csv("../data/shiny_tables/access_indices/transit_index_disability.csv")
```

###An example of a new datafile

The following chunk of code doesn't need to be run, but demonstrates how we created the "example_new_program_list.csv" file. Specifically, we session at a new address, and delete five elsewhere. We end up with one new unique address, but five fewer sessions at pre-existing addresses.
```{r eval=FALSE}
#We would do this if we were reading a csv

#new_reschool_programs <- read.csv("location.csv",header=TRUE,stringsAsFactors = FALSE) #replace with a real location obvs

#here we make a new test session with a new address to verify that our code works
new_reschool_programs <- reschool_programs
new_reschool_programs <- rbind(new_reschool_programs[nrow(new_reschool_programs),],new_reschool_programs) #we add a duplicate to the last program here
new_reschool_programs[nrow(new_reschool_programs),"long"] <- -104.931324
new_reschool_programs[nrow(new_reschool_programs),"lat"] <- 39.715399
new_reschool_programs[nrow(new_reschool_programs),"session_address_1"] <- "50 S Dahlia St"
new_reschool_programs[nrow(new_reschool_programs),"session_name"] <- "Test_Session"

#here we delete five arbitary programs
new_reschool_programs <- new_reschool_programs[-c(1,100,950,2,200),]

#then we aggregate to new addresses
new_reschool_addresses <- new_reschool_programs[,c("session_address_1","lat","long")] #subset to what we need
new_reschool_addresses <- unique(new_reschool_addresses)

#and finally we do some validation to confirm changes in our data, there should be fewer rows in new reschool programs, but one more unqiue address
length(unique(new_reschool_addresses$session_address_1)) #note we have one new address now
length(unique(reschool_addresses$session_address_1))
nrow(new_reschool_programs)
nrow(reschool_programs)

write.csv(new_reschool_programs, "example_new_program_list.csv")
```

###Find New Programs
We run a quick loop here to identify new programs so that we can compute new distances as needed. 
```{r}
#aggregate to new addresses
new_reschool_addresses <- new_reschool_programs[,c("session_address_1","lat","long")] #subset to what we need
new_reschool_addresses <- unique(new_reschool_addresses)

#Make empty vectors to store new addresses
address_vector <- c()
lat_vector <- c()
long_vector <- c()

#loop for new addresses
for (i in 1:nrow(new_reschool_addresses)){
  test_address <- new_reschool_addresses$session_address_1[i] #define each addresses / lat/long
  test_lat <- new_reschool_addresses$lat[i]
  test_long <- new_reschool_addresses$long[i]
  if(any(reschool_programs$session_address_1==test_address)==FALSE){ #check if matches any precomputed
    address_vector <- append(address_vector,test_address) #append accordingly
    lat_vector <- append(lat_vector, test_lat)
    long_vector <- append(long_vector, test_long)
  }
  if (i %% 100 == 0){
    print(paste(i,"working..."))
  }
}

# if there are no new addresses to add, then great!
if (is.null(new_programs)){
  print("No new addresses!")
} else {
  # if there are new addresses, we have to get to work. First, we print the new program address as a 
  # sanity check
  new_programs <- data.frame(address_vector,lat_vector,long_vector)
  colnames(new_programs) <- c("session_address_1","lat","long")
  head(new_programs)
  
  

  ######### Get census block group centroids for the oncoming calculation #########
  library(rgeos)
  library(rgdal)
  library(raster)
  library(tidyverse)
  
  spdf <- readOGR("../data/census_block_groups/shape_census.shp")
  census_centroids <- SpatialPointsDataFrame(gCentroid(spdf, byid=TRUE), spdf@data, match.ID = FALSE)
  census_centroids <- as.data.frame(census_centroids)
  colnames(census_centroids)[colnames(census_centroids)=="x"] <- "long"  # for consistency across files
  colnames(census_centroids)[colnames(census_centroids)=="y"] <- "lat"
  census_centroids <- census_centroids[,c("Id2", "lat", "long")]
  colnames(census_centroids)[colnames(census_centroids)=="Id2"] <- "blockID" #updating for loop consistency
  #################################################################################
  
  
  
  
  ######### Calculate distances for new programs #########
  library(googleway)
  new_block_distance <- new_programs
  arrival_time <- as.POSIXct(paste((Sys.Date()+1),"07:00:00")) #we need to set this to always be greater than the start date or the call for transit time breaks. 
  
  #for ease of testing
  new_block_distance$blockID <- 0
  new_block_distance$driving_morning <- 0
  new_block_distance$walking_morning <- 0
  new_block_distance$transit_morning <- 0
  new_block_distance$kilometers <- 0
  
  system.time(for (i in 1:nrow(census_centroids)){  
    #to be replaced length(census_centroids), i.e, read every unique block centroid
    blockgroup.i <- census_centroids$blockID[i] #read arbitrary block ID
    lat.i <- census_centroids$lat[i] #get coordinates
    long.i <- census_centroids$long[i]
    lat.long <- c(lat.i,long.i) #combine blockgroup coordinates for mapdist function
    lat.long <- paste(lat.long,collapse=" ") #see above
    block_mover <- subset(new_block_distance,new_block_distance$blockID==0) #make a new subset that is original length
    for (x in 1:nrow(block_mover)){
      #setting up block subset
      block_mover$blockID <- blockgroup.i
      lat.x <- block_mover$lat[x] #get coordinates for OSRs
      long.x <- block_mover$lon[x] 
      block_mover$blockID <- blockgroup.i #set ID blockgroup ID
      lat.long.x <- c(lat.x,long.x) #combine OSR coordinates for use in mapdist
      lat.long.x <- paste(lat.long.x,collapse=" ")
      #distance calculations with arrival time = 08:00am on a weekday
      distance.x <- google_distance(origin=c(lat.i,long.i),
                                    destination = c(lat.x,long.x),
                                    mode="driving",
                                    arrival_time = arrival_time, #autocorrect to PST, so we adjust for the dif from MST to MT
                                    key = google_api_key)
      distance_walking.x <- google_distance(origin=c(lat.i,long.i),
                                            destination = c(lat.x,long.x),
                                            mode="walking",
                                            arrival_time = arrival_time,
                                            key = google_api_key)
      distance_transit.x <- google_distance(origin=c(lat.i,long.i),
                                            destination = c(lat.x,long.x),
                                            mode="transit",
                                            arrival_time = arrival_time,
                                            key = google_api_key)
      #grabbing our dataframe list items
      distance.x <- as.data.frame(distance.x$rows$elements)
      distance_walking.x <- as.data.frame(distance_walking.x$rows$elements)
      distance_transit.x <- as.data.frame(distance_transit.x$rows$elements)
      if(distance_transit.x$status!="ZERO_RESULTS"){
        block_mover$transit_morning[x] <- as.numeric(distance_transit.x$duration[2]/60)}
      #indexing the piece of the dataframes we need
      block_mover$driving_morning[x] <- as.numeric(distance.x$duration[2]/60) #paste drive time, etc, in minutes
      block_mover$walking_morning[x] <- as.numeric(distance_walking.x$duration[2]/60)
      block_mover$kilometers[x] <- distance.x$distance[[1]]
      if(i %% 50 == 0){
        print(paste("working...",x,i))
        print(nrow(new_block_distance))#print iterations to note breaks in case something goes wrong with the maps api 
      }
  }
    new_block_distance <- rbind(new_block_distance,block_mover) #merge new distance into the base dataframe
    })
  
  new_block_distance <- subset(new_block_distance,new_block_distance$blockID!=0)
  colnames(new_block_distance)[colnames(new_block_distance)=="blockID"] <- "Id2"
  ########################################################
  
  ###Clean New Distances
  #Quick validator to ensure there's no duplicates, that 0s are NAs, and that kilometeres are numeric. 
  library(stringr)
  new_block_distance <- unique(new_block_distance) #remove any duplicates in case we had to start and stop a few block ID choices in the loop
  new_block_distance$meters <- grepl(" m",new_block_distance$kilometers) #identify which are no kms for use in function
  new_block_distance$distance <- 0 #empty dataframe to store new distances
  
  #for loop to remove distance characters, cus the hell with sapply
  for (x in 1:nrow(new_block_distance)){
    if(new_block_distance$meters[x]==FALSE){
      km <- as.numeric(str_split_fixed(new_block_distance$kilometers[x]," ",2)[,1])
      new_block_distance$distance[x] <- km}
    if(new_block_distance$meters[x]==TRUE){
      m <- as.numeric(str_split_fixed(new_block_distance$kilometers[x]," ",2)[,1])/1000
      new_block_distance$distance[x] <- m
    }
    if(x %% 100 == 0 ){
      print(paste("working....",x))
    }
  }
  
  #convert distance to numeric and remove placeholder columns
  new_block_distance$distance <- as.numeric(new_block_distance$distance)
  new_block_distance$kilometers <- new_block_distance$distance
  new_block_distance$distance <- NULL
  new_block_distance$meters <- NULL
  
  #convert transit time = 0 to NA as it should be 
  new_block_distance$transit_morning[new_block_distance$transit_morning == 0] <- NA
  
  
  
  
  ####################### Merge new distances with old #######################
  block_distance <- merge(new_block_distance,block_distance,by=c("Id2","session_address_1","driving_morning","walking_morning","transit_morning","lat","long"),all=TRUE)
  ############################################################################
  
  
  
  
  ################ Set cost thresholds for new reschool programs ################
  new_reschool_programs$academic <- new_reschool_programs$has_academic==TRUE | new_reschool_programs$has_stem==TRUE
  
  new_reschool_programs$art <- new_reschool_programs$has_arts==TRUE | new_reschool_programs$has_cooking==TRUE | new_reschool_programs$has_dance==TRUE | new_reschool_programs$has_drama==TRUE | new_reschool_programs$has_music==TRUE
  
  #cost thresolds, to be updated w/ time data from selam
  new_reschool_programs$free <- new_reschool_programs$session_cost==0
  new_reschool_programs$lowcost <- new_reschool_programs$cost_per_day<=50
  new_reschool_programs$anycost <- TRUE
  
  #establishing "1" per row for use in aggergation
  new_reschool_programs$n <- 1 
  ###############################################################################
}
```

Second, we perform the actual access index calculations. 

Before we do that, we have to create some helping functions:
```{r}
Merge_Set <- function(dataframe){
  relevant_columns <- c("Id2","session_address_1","driving_morning","walking_morning","transit_morning","kilometers","block_lat","block_long")
  block_distance_new <- block_distance[,relevant_columns] #here we're cutting duplicate program_addresses, and other antiquated info (previous aggregations, PCT vhcl ownership) that was use in previous calculations
  temp <- merge(block_distance_new,dataframe,all.y=TRUE)
  temp$n[is.na(temp$n)==TRUE] <- 0
  return(temp)
}

# Subsets the dataset for different types of access index (i.e. by type and cost)
Make_Subset <- function(dataframe,type=NULL,cost=NULL){
  dataframe$n <- 1
  if(is.null(type)){
    dataframe <- dataframe
    }
  if(length(type)==1){
    dataframe <- dataframe[dataframe[,type],]
  }
  if(length(type)>1){
    dataframe <- dataframe[apply(FUN=any,X=dataframe[,c(type)],MARGIN=1),]
  }
  if(is.null(cost)){
    return(dataframe)
  }
  else{
     dataframe <- dataframe <- dataframe[dataframe[,cost],]
  }
}

# Aggregates the data 
Aggregate_Subset <- function(dataframe){
  return(aggregate(n ~ session_address_1+lat+long, data=dataframe,FUN=sum)) #note that "n" in this case ==1 per row, which n this case corresponds to one unique program session
}

decay_fxn_softGravity <- function(dataframe,mode){
  if (mode=="transit") {
    scale = 10
    column="transit_morning"
  }
  if (mode=="drive"){
    scale = 10
    column="driving_morning"
  }
  mode=mode
  dataframe[,"n"]*(1/(1+(dataframe[,column]/scale))^2)
}

normalize <- function(vec,max) {
  return((vec/max)*100)
}
```

Then we can create the access indices for driving and for transit. 
```{r}
base_frame <- data.frame("Id2"=spdf@data$Id2)
#Create driving frame
new_driving_index <- base_frame

#Creating categories list for loop
categories <- c("academic","art","has_sports","has_nature")

#Creating cost list for loop
costs <- c("free","lowcost","anycost")

#Loop for all categories and costs
for (i in 1:length(categories)){
  type <- categories[i]
  for (x in 1:length(costs)){
    cost <- costs[x]
    user_set <- Make_Subset(new_reschool_programs,type,cost)
    agg_set <- Aggregate_Subset(user_set)
    merged_set <- Merge_Set(agg_set)
    merged_set$AccessIndex <- decay_fxn_softGravity(merged_set,"drive") 
    summary_index_user <- aggregate(AccessIndex ~ Id2,data=merged_set,FUN=sum) 
    max_access <- max(summary_index_user$AccessIndex)
    #update colnames for merge
    summary_index_user$AccessIndex <- normalize(summary_index_user$AccessIndex,max_access)
    colnames(summary_index_user)[colnames(summary_index_user)=="AccessIndex"] <- paste("AI",type,cost,sep = "_") #flexible name writing for loop
    summary_index_user$Id2 <- as.numeric(summary_index_user$Id2) #matching str to baseframe 
    new_driving_index <- merge(summary_index_user,new_driving_index,by=c("Id2"))
  }
  print(paste(i,"working"))
  if(length(new_driving_index)>11){
    print(colnames(new_driving_index))
  }
}

#Create an overall average by category with no cost
new_driving_index$AI_overall <- rowMeans(new_driving_index[,c("AI_has_nature_anycost",'AI_has_sports_anycost','AI_art_anycost','AI_academic_anycost')])
new_driving_index$AI_overall_free <- rowMeans(new_driving_index[,c("AI_has_nature_free","AI_has_sports_free","AI_art_free","AI_academic_free")])

#Create driving frame
new_transit_index <- base_frame

#Creating categories list for loop
categories <- c("academic","art","has_sports","has_nature")

#Creating cost list for loop
costs <- c("free","lowcost","anycost")

#Loop for all categories and costs
for (i in 1:length(categories)){
  type <- categories[i]
  for (x in 1:length(costs)){
    cost <- costs[x]
    user_set <- Make_Subset(new_reschool_programs,type,cost)
    agg_set <- Aggregate_Subset(user_set)
    merged_set <- Merge_Set(agg_set)
    
    #replace na and 0 transit times with wallking times
    merged_set <- subset(merged_set,is.na(merged_set$walking_morning)==FALSE)
    merged_set$transit_morning[is.na(merged_set$transit_morning)] <- merged_set$walking_morning[is.na(merged_set$transit_morning)] #there shouldn't be NAs or 0s
    merged_set$transit_morning[merged_set$transit_morning==0] <- merged_set$walking_morning[merged_set$transit_morning==0] #but if there is, as sometimes occurs with the API calls,        here we replace non-existant transit times with walking times, under the assumption the purpose of this index is to view access for individuals without a car
    
    merged_set$AccessIndex <- decay_fxn_softGravity(merged_set,"transit") 
    merged_set$CarAccess <- decay_fxn_softGravity(merged_set,"drive")
    
    summary_index_user_transit_graphic <- aggregate(CarAccess ~ Id2,data=merged_set,FUN=sum)
    summary_index_user_transit <- aggregate(AccessIndex ~ Id2,data=merged_set,FUN=sum)

    #normalize, note here we make two columns, one to compare to driving, one for visual rep
    max_access <- max(summary_index_user_transit_graphic$CarAccess)
    summary_index_user_transit$AccessIndex <- normalize(summary_index_user_transit$AccessIndex,max_access)
    
    #update colnames for merge
    colnames(summary_index_user_transit)[colnames(summary_index_user_transit)=="AccessIndex"] <- paste("AI",type,cost,sep = "_") #flexible name writing for loop
    summary_index_user_transit$Id2 <- as.numeric(summary_index_user_transit$Id2) #matching str to baseframe 
    new_transit_index <- merge(summary_index_user_transit,new_transit_index,by=c("Id2"))
  }
  print(paste(i,"working"))
  if(length(new_transit_index)>11){
    print(colnames(new_transit_index))
  }
}

#Create an overall average by category with no cost
new_transit_index$AI_overall <- rowMeans(new_transit_index[,c("AI_has_nature_anycost",'AI_has_sports_anycost','AI_art_anycost','AI_academic_anycost')])
new_transit_index$AI_overall_free <- rowMeans(new_transit_index[,c("AI_has_nature_free","AI_has_sports_free","AI_art_free","AI_academic_free")])
```

###Overwrite existing index
```{r}
# then overwrite the old indices
#write.csv(new_driving_index,"../data/shiny_tables/access_indices/driving_index.csv")
#write.csv(new_transit_index,"../data/shiny_tables/access_indices/transit_index.csv")
```

Finally, do the same thing for programs with disabilities. 
```{r}
new_reschool_programs_disability <- subset(new_reschool_programs,new_reschool_programs$has_special_needs_offerings==TRUE)

base_frame <- data.frame("Id2"=spdf@data$Id2)
#Create driving frame
new_driving_index <- base_frame

#Creating categories list for loop
categories <- c("academic","art","has_sports","has_nature")

#Creating cost list for loop
costs <- c("free","lowcost","anycost")

#Loop for all categories and costs
for (i in 1:length(categories)){
  type <- categories[i]
  for (x in 1:length(costs)){
    cost <- costs[x]
    user_set <- Make_Subset(new_reschool_programs_disability,type,cost)
    agg_set <- Aggregate_Subset(user_set)
    merged_set <- Merge_Set(agg_set)
    merged_set$AccessIndex <- decay_fxn_softGravity(merged_set,"drive") 
    summary_index_user <- aggregate(AccessIndex ~ Id2,data=merged_set,FUN=sum) 
    max_access <- max(summary_index_user$AccessIndex)
    #update colnames for merge
    summary_index_user$AccessIndex <- normalize(summary_index_user$AccessIndex,max_access)
    colnames(summary_index_user)[colnames(summary_index_user)=="AccessIndex"] <- paste("AI",type,cost,sep = "_") #flexible name writing for loop
    summary_index_user$Id2 <- as.numeric(summary_index_user$Id2) #matching str to baseframe 
    new_driving_index <- merge(summary_index_user,new_driving_index,by=c("Id2"))
  }
  print(paste(i,"working"))
  if(length(new_driving_index)>11){
    print(colnames(new_driving_index))
  }
}

#Create an overall average by category with no cost
new_driving_index$AI_overall <- rowMeans(new_driving_index[,c("AI_has_nature_anycost",'AI_has_sports_anycost','AI_art_anycost','AI_academic_anycost')])
new_driving_index$AI_overall_free <- rowMeans(new_driving_index[,c("AI_has_nature_free","AI_has_sports_free","AI_art_free","AI_academic_free")])

#Create driving frame
new_transit_index <- base_frame

#Creating categories list for loop
categories <- c("academic","art","has_sports","has_nature")

#Creating cost list for loop
costs <- c("free","lowcost","anycost")

#Loop for all categories and costs
for (i in 1:length(categories)){
  type <- categories[i]
  for (x in 1:length(costs)){
    cost <- costs[x]
    user_set <- Make_Subset(new_reschool_programs_disability,type,cost)
    agg_set <- Aggregate_Subset(user_set)
    merged_set <- Merge_Set(agg_set)
    
    #replace na and 0 transit times with wallking times
    merged_set <- subset(merged_set,is.na(merged_set$walking_morning)==FALSE)
    merged_set$transit_morning[is.na(merged_set$transit_morning)] <- merged_set$walking_morning[is.na(merged_set$transit_morning)] #there shouldn't be NAs or 0s
    merged_set$transit_morning[merged_set$transit_morning==0] <- merged_set$walking_morning[merged_set$transit_morning==0] #but if there is, as sometimes occurs with the API calls,        here we replace non-existant transit times with walking times, under the assumption the purpose of this index is to view access for individuals without a car
    
    merged_set$AccessIndex <- decay_fxn_softGravity(merged_set,"transit") 
    merged_set$CarAccess <- decay_fxn_softGravity(merged_set,"drive")
    
    summary_index_user_transit_graphic <- aggregate(CarAccess ~ Id2,data=merged_set,FUN=sum)
    summary_index_user_transit <- aggregate(AccessIndex ~ Id2,data=merged_set,FUN=sum)

    #normalize, note here we make two columns, one to compare to driving, one for visual rep
    max_access <- max(summary_index_user_transit_graphic$CarAccess)
    summary_index_user_transit$AccessIndex <- normalize(summary_index_user_transit$AccessIndex,max_access)
    
    #update colnames for merge
    colnames(summary_index_user_transit)[colnames(summary_index_user_transit)=="AccessIndex"] <- paste("AI",type,cost,sep = "_") #flexible name writing for loop
    summary_index_user_transit$Id2 <- as.numeric(summary_index_user_transit$Id2) #matching str to baseframe 
    new_transit_index <- merge(summary_index_user_transit,new_transit_index,by=c("Id2"))
  }
  print(paste(i,"working"))
  if(length(new_transit_index)>11){
    print(colnames(new_transit_index))
  }
}

#Create an overall average by category with no cost
new_transit_index$AI_overall <- rowMeans(new_transit_index[,c("AI_has_nature_anycost",'AI_has_sports_anycost','AI_art_anycost','AI_academic_anycost')])
new_transit_index$AI_overall_free <- rowMeans(new_transit_index[,c("AI_has_nature_free","AI_has_sports_free","AI_art_free","AI_academic_free")])
```

And then save that:
```{r}
# then overwrite the old indices
#write.csv(new_driving_index,"../data/shiny_tables/access_indices/driving_index_disability.csv")
#write.csv(new_transit_index,"../data/shiny_tables/access_indices/transit_index_disability.csv")
```

Finally, update the block distances
```{r}
#write.csv(block_distance, "../data/shiny_tables/block_distance.csv")
```